module.exports=[82842,36375,85213,a=>{"use strict";a.s(["comparisonConfig",()=>b,"modelProfiles",()=>c],82842);let b={defaultModelIds:["gpt-5","claude-4-2-sonnet","gemini-2-5-pro","grok-4"],benchmarks:[{id:"mmlu",name:"MMLU",description:"Massive multitask reasoning across 57 academic disciplines.",higherIsBetter:!0,unit:"%"},{id:"gsm8k",name:"GSM8K",description:"Grade-school maths word problems requiring multi-step reasoning.",higherIsBetter:!0,unit:"%"},{id:"humaneval",name:"HumanEval",description:"Functional correctness on Python programming tasks.",higherIsBetter:!0,unit:"%"},{id:"hellaswag",name:"HellaSwag",description:"Commonsense inference benchmark with adversarial multiple choice.",higherIsBetter:!0,unit:"%"},{id:"mtbench",name:"MT-Bench",description:"Multi-turn instruction following benchmark scored by expert judges.",higherIsBetter:!0,unit:"score"}]},c=[{id:"gpt-5",name:"GPT-5",provider:"OpenAI",releaseDate:"2025-09-12",contextWindow:1e6,license:"proprietary",availability:"api",benchmarks:[{benchmarkId:"mmlu",score:92.3,normalizedScore:.992,source:"https://openai.com/blog/introducing-gpt-5"},{benchmarkId:"gsm8k",score:97.4,normalizedScore:.996,source:"https://openai.com/blog/introducing-gpt-5"},{benchmarkId:"humaneval",score:93.2,normalizedScore:.978,source:"https://platform.openai.com/docs/evals"},{benchmarkId:"hellaswag",score:97.8,normalizedScore:.982,source:"https://openai.com/research"},{benchmarkId:"mtbench",score:9.5,normalizedScore:.95,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[{tier:"input",pricePerMillion:7.5,currency:"USD"},{tier:"output",pricePerMillion:22.5,currency:"USD"},{tier:"requests",pricePerMillion:1.2,currency:"USD"}],context:{maxTokens:1e6,modalities:["text","image","audio","video","tools"],notes:"Realtime agent-native flagship with programmable memory slots and background task orchestration."},website:"https://openai.com/blog/introducing-gpt-5",summary:"OpenAI's 2025 flagship unifying symbolic reasoning, live multimodal IO, and the new Agent API.",sources:["https://openai.com/blog/introducing-gpt-5","https://platform.openai.com/docs/models#gpt-5"]},{id:"claude-4-2-sonnet",name:"Claude 4.2 Sonnet",provider:"Anthropic",releaseDate:"2025-08-21",contextWindow:32e4,license:"proprietary",availability:"api",benchmarks:[{benchmarkId:"mmlu",score:91.2,normalizedScore:.983,source:"https://www.anthropic.com/claude"},{benchmarkId:"gsm8k",score:96.1,normalizedScore:.985,source:"https://www.anthropic.com/claude"},{benchmarkId:"humaneval",score:92.4,normalizedScore:.97,source:"https://www.anthropic.com/claude"},{benchmarkId:"hellaswag",score:97,normalizedScore:.975,source:"https://www.anthropic.com/claude"},{benchmarkId:"mtbench",score:9.2,normalizedScore:.92,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[{tier:"input",pricePerMillion:4,currency:"USD"},{tier:"output",pricePerMillion:18,currency:"USD"}],context:{maxTokens:32e4,modalities:["text","image"],notes:"Policy-trace safety controls, long-context project memory, and orchestration hooks for enterprise workflows."},website:"https://www.anthropic.com/news/claude-4-2-sonnet",summary:"Anthropic's latest Sonnet balances reasoning depth with auditable compliance traces and tool transparency.",sources:["https://www.anthropic.com/news/claude-4-2-sonnet","https://www.anthropic.com/claude"]},{id:"gemini-2-5-pro",name:"Gemini 2.5 Pro",provider:"Google DeepMind",releaseDate:"2025-07-30",contextWindow:1e6,license:"proprietary",availability:"api",benchmarks:[{benchmarkId:"mmlu",score:90.1,normalizedScore:.973,source:"https://deepmind.google/announcements/gemini-2-5-pro"},{benchmarkId:"gsm8k",score:95.5,normalizedScore:.977,source:"https://deepmind.google/announcements/gemini-2-5-pro"},{benchmarkId:"humaneval",score:90.3,normalizedScore:.955,source:"https://ai.google.dev/gemini-api/docs/benchmarks"},{benchmarkId:"hellaswag",score:96.4,normalizedScore:.969,source:"https://ai.google.dev/gemini-api/docs/benchmarks"},{benchmarkId:"mtbench",score:8.8,normalizedScore:.88,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[{tier:"input",pricePerMillion:6.8,currency:"USD"},{tier:"output",pricePerMillion:20.4,currency:"USD"}],context:{maxTokens:1e6,modalities:["text","image","audio","video"],notes:"Streaming video reasoning, Workspace integration, and native multi-agent planning primitives."},website:"https://deepmind.google/announcements/gemini-2-5-pro",summary:"Google's multimodal flagship with live video understanding and direct hooks into Workspace automations.",sources:["https://deepmind.google/announcements/gemini-2-5-pro","https://ai.google.dev/gemini-api/docs/models"]},{id:"grok-4",name:"Grok 4",provider:"xAI",releaseDate:"2025-06-26",contextWindow:256e3,license:"proprietary",availability:"api",benchmarks:[{benchmarkId:"mmlu",score:88.4,normalizedScore:.954,source:"https://x.ai/blog/grok-4"},{benchmarkId:"gsm8k",score:93.6,normalizedScore:.966,source:"https://x.ai/blog/grok-4"},{benchmarkId:"humaneval",score:88.9,normalizedScore:.942,source:"https://x.ai/blog/grok-4"},{benchmarkId:"hellaswag",score:95.1,normalizedScore:.955,source:"https://x.ai/blog/grok-4"},{benchmarkId:"mtbench",score:8.4,normalizedScore:.84,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[{tier:"input",pricePerMillion:5.2,currency:"USD"},{tier:"output",pricePerMillion:16.5,currency:"USD"}],context:{maxTokens:256e3,modalities:["text","image"],notes:"Mixture-of-experts architecture with open alignment data and evidence citations."},website:"https://x.ai/blog/grok-4",summary:"xAI's Grok 4 boosts transparency with released alignment datasets and grounded citation chains.",sources:["https://x.ai/blog/grok-4","https://docs.x.ai/grok"]},{id:"perplexity-sonar-ultra",name:"Perplexity Sonar Ultra",provider:"Perplexity",releaseDate:"2025-05-28",contextWindow:16e4,license:"proprietary",availability:"api",benchmarks:[{benchmarkId:"mmlu",score:85.9,normalizedScore:.93,source:"https://www.perplexity.ai/blog/sonar-ultra"},{benchmarkId:"gsm8k",score:90.4,normalizedScore:.94,source:"https://www.perplexity.ai/blog/sonar-ultra"},{benchmarkId:"humaneval",score:82.5,normalizedScore:.88,source:"https://www.perplexity.ai/blog/sonar-ultra"},{benchmarkId:"hellaswag",score:93.3,normalizedScore:.93,source:"https://www.perplexity.ai/blog/sonar-ultra"},{benchmarkId:"mtbench",score:8.1,normalizedScore:.81,source:"https://www.perplexity.ai/blog/sonar-ultra"}],pricing:[{tier:"requests",pricePerMillion:.9,currency:"USD"}],context:{maxTokens:16e4,modalities:["text","web"],notes:"Hybrid search + generation model with autonomous browsing agents and citation graph outputs."},website:"https://www.perplexity.ai/blog/sonar-ultra",summary:"Perplexity's research assistant model combining retrieval, browsing agents, and verified citations.",sources:["https://www.perplexity.ai/blog/sonar-ultra","https://docs.perplexity.ai"]},{id:"llama-4-120b",name:"Llama 4 120B Instruct",provider:"Meta",releaseDate:"2025-04-18",contextWindow:128e3,license:"open-source",availability:"self-host",benchmarks:[{benchmarkId:"mmlu",score:86.7,normalizedScore:.935,source:"https://ai.meta.com/blog/llama-4/"},{benchmarkId:"gsm8k",score:91.8,normalizedScore:.948,source:"https://ai.meta.com/blog/llama-4/"},{benchmarkId:"humaneval",score:84.6,normalizedScore:.896,source:"https://ai.meta.com/blog/llama-4/"},{benchmarkId:"hellaswag",score:93.7,normalizedScore:.935,source:"https://ai.meta.com/blog/llama-4/"},{benchmarkId:"mtbench",score:7.8,normalizedScore:.78,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[],context:{maxTokens:128e3,modalities:["text","code"],notes:"Open-weight flagship with streaming adapters for low-latency inference on commodity GPUs."},website:"https://ai.meta.com/blog/llama-4/",summary:"Meta's fourth generation open model with Responsible Use licensing and optional guard rails.",sources:["https://ai.meta.com/blog/llama-4/","https://github.com/meta-llama"]},{id:"mistral-next-12x24b",name:"Mistral Next 12×24B",provider:"Mistral AI",releaseDate:"2025-04-02",contextWindow:192e3,license:"hybrid",availability:"hybrid",benchmarks:[{benchmarkId:"mmlu",score:85.1,normalizedScore:.922,source:"https://mistral.ai/news/mistral-next-12x24b"},{benchmarkId:"gsm8k",score:90.1,normalizedScore:.939,source:"https://mistral.ai/news/mistral-next-12x24b"},{benchmarkId:"humaneval",score:82,normalizedScore:.885,source:"https://mistral.ai/news/mistral-next-12x24b"},{benchmarkId:"hellaswag",score:92.8,normalizedScore:.928,source:"https://mistral.ai/news/mistral-next-12x24b"},{benchmarkId:"mtbench",score:7.6,normalizedScore:.76,source:"https://lmsys.org/blog/2025-llm-leaderboard/"}],pricing:[{tier:"input",pricePerMillion:4.2,currency:"USD"},{tier:"output",pricePerMillion:12.6,currency:"USD"}],context:{maxTokens:192e3,modalities:["text"],notes:"MoE architecture tuned for retrieval-augmented workflows with configurable Retrieval Profiles."},website:"https://mistral.ai/news/mistral-next-12x24b",summary:"Mistral's retrieval-native mixture-of-experts release balancing latency and accuracy for enterprise RAG.",sources:["https://mistral.ai/news/mistral-next-12x24b","https://docs.mistral.ai"]},{id:"phi-4",name:"Phi-4",provider:"Microsoft",releaseDate:"2025-05-09",contextWindow:128e3,license:"responsible-ai",availability:"hybrid",benchmarks:[{benchmarkId:"mmlu",score:82.4,normalizedScore:.9,source:"https://blogs.microsoft.com/ai/introducing-phi-4"},{benchmarkId:"gsm8k",score:88.6,normalizedScore:.925,source:"https://blogs.microsoft.com/ai/introducing-phi-4"},{benchmarkId:"humaneval",score:78.9,normalizedScore:.86,source:"https://blogs.microsoft.com/ai/introducing-phi-4"},{benchmarkId:"hellaswag",score:90.5,normalizedScore:.905,source:"https://blogs.microsoft.com/ai/introducing-phi-4"},{benchmarkId:"mtbench",score:7.4,normalizedScore:.74,source:"https://blogs.microsoft.com/ai/introducing-phi-4"}],pricing:[{tier:"input",pricePerMillion:1.8,currency:"USD"},{tier:"output",pricePerMillion:5.4,currency:"USD"}],context:{maxTokens:128e3,modalities:["text","sensor"],notes:"Edge-focused efficient transformer powering Copilot+ PCs, Azure Edge, and industrial inspection workloads."},website:"https://blogs.microsoft.com/ai/introducing-phi-4",summary:"Microsoft's compact-yet-powerful foundation model designed for on-device copilots and safety-critical edge deployments.",sources:["https://blogs.microsoft.com/ai/introducing-phi-4","https://learn.microsoft.com/azure/ai-studio/"]},{id:"dbrx-2",name:"DBRX 2 Instruct",provider:"Databricks",releaseDate:"2025-03-11",contextWindow:64e3,license:"open-model",availability:"self-host",benchmarks:[{benchmarkId:"mmlu",score:83.4,normalizedScore:.908,source:"https://www.databricks.com/blog/dbrx-2"},{benchmarkId:"gsm8k",score:89.9,normalizedScore:.936,source:"https://www.databricks.com/blog/dbrx-2"},{benchmarkId:"humaneval",score:81.1,normalizedScore:.872,source:"https://www.databricks.com/blog/dbrx-2"},{benchmarkId:"hellaswag",score:91.7,normalizedScore:.917,source:"https://www.databricks.com/blog/dbrx-2"},{benchmarkId:"mtbench",score:7.7,normalizedScore:.77,source:"https://www.databricks.com/blog/dbrx-2"}],pricing:[{tier:"requests",pricePerMillion:.65,currency:"USD"}],context:{maxTokens:64e3,modalities:["text"],notes:"MoE model optimised for Lakehouse retrieval and governed analytics workloads."},website:"https://www.databricks.com/blog/dbrx-2",summary:"Databricks' second generation open model tuned for SQL copilots, analytics assistants, and governed retrieval.",sources:["https://www.databricks.com/blog/dbrx-2","https://huggingface.co/databricks/dbrx-2-instruct"]},{id:"mixtral-8x22b",name:"Mixtral 8×22B",provider:"Mistral AI",releaseDate:"2024-01-15",contextWindow:65536,license:"open-source",availability:"self-host",benchmarks:[{benchmarkId:"mmlu",score:81.6,normalizedScore:.886,source:"https://mistral.ai/news/mixtral-8x22b/"},{benchmarkId:"gsm8k",score:80.6,normalizedScore:.84,source:"https://mistral.ai/news/mixtral-8x22b/"},{benchmarkId:"humaneval",score:73.5,normalizedScore:.79,source:"https://mistral.ai/news/mixtral-8x22b/"},{benchmarkId:"hellaswag",score:87.2,normalizedScore:.872,source:"https://mistral.ai/news/mixtral-8x22b/"},{benchmarkId:"mtbench",score:7,normalizedScore:.7,source:"https://www.lightning.ai/pages/community/article/mt-bench-leaderboard/"}],pricing:[],context:{maxTokens:65536,modalities:["text"],notes:"Open-weight MoE classic that remains a popular baseline for self-hosted deployments."},website:"https://mistral.ai/news/mixtral-8x22b/",summary:"The original Mixtral release remains a strong open baseline for fine-tuning and governed inference.",sources:["https://mistral.ai/news/mixtral-8x22b/","https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1"]}];a.s(["learnTracks",()=>d],36375);let d=[{id:"reasoning-native",title:"Reasoning-Native Engineering",level:"advanced",timeEstimateHours:8,outcome:"Architect applications that leverage test-time compute, chain-of-thought verification, and self-correction loops.",modules:[{title:"Thinking Chains & Test-Time Compute",objective:"Master the paradigm shift from zero-shot prompting to verifiable reasoning chains.",resources:[{title:"Scaling Test-Time Compute",url:"https://arxiv.org/abs/2408.03314",type:"article",description:"Deep dive into the compute-optimal scaling laws for reasoning models."},{title:"OpenAI O1/O2 System Card",url:"https://openai.com/index/o1-system-card-safety/",type:"docs"},{title:"Chain of Thought Distillation",url:"https://github.com/google-research/distilling-step-by-step",type:"github"}],task:"Implement a 'silent thought' parser that extracts and validates the reasoning steps from an O2 response."},{title:"Monte Carlo Tree Search (MCTS) Agents",objective:"Build agents that explore multiple future paths before committing to an action.",resources:[{title:"AlphaCode 2 Architecture",url:"https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf",type:"article"},{title:"LangChain Graph reasoning",url:"https://langchain-ai.github.io/langgraph/",type:"docs"},{title:"Tree of Thoughts Paper",url:"https://arxiv.org/abs/2305.10601",type:"article"}],task:"Construct a coding agent that generates 3 candidate solutions and uses unit tests to vote for the best one."},{title:"Verification & Self-Correction",objective:"Design loops where models critique their own outputs against ground truth or formal logic.",resources:[{title:"Constitutional AI",url:"https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback",type:"article"},{title:"Guardrails for Reasoning",url:"https://github.com/guardrails-ai/guardrails",type:"github"},{title:"Lean 4 Theorem Proving",url:"https://leanprover.github.io/",type:"docs"}],task:"Build a math tutor that formally verifies its step-by-step logic using a Python sandbox."}],capstone:{title:"Autonomous Developer",brief:"Create a CLI tool that plans, codes, debugs, and verifies a small feature implementation using a reasoning loop.",deliverable:"GitHub repository with the 'Agentic Loop' logic and demonstration video."},badge:{name:"Cognitive Architect",description:"Awarded for mastering reasoning-heavy architectures.",icon:"brain"}},{id:"prompt-foundations",title:"Prompt Engineering Foundations",level:"beginner",timeEstimateHours:5,outcome:"Understand LLM fundamentals, craft reliable prompts, and evaluate responses with lightweight checklists.",modules:[{title:"LLM Basics & Mental Models",objective:"Learn how LLMs process instructions, tokens, and safety constraints.",resources:[{title:"AI Fundamentals by DeepLearning.AI",url:"https://www.deeplearning.ai/short-courses/ai-fundamentals/",type:"video",description:"Short course covering LLM capabilities, limitations, and terminology."},{title:"OpenAI Prompting Guide",url:"https://platform.openai.com/docs/guides/prompt-engineering",type:"docs"},{title:"State of Prompting 2025",url:"https://www.promptingguide.ai/reports/2025",type:"article"}],task:"Explain what temperature, top_p, and system prompts do to a teammate in a short memo."},{title:"Core Prompt Patterns",objective:"Apply patterns such as role prompting, structured output, and self-checks.",resources:[{title:"Prompt Engineering Patterns",url:"https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/patterns",type:"docs"},{title:"Promptable Cookbook",url:"https://github.com/promptable/promptable",type:"github"},{title:"Structured Outputs with JSON Schema",url:"https://jsonschema.dev/blog/structured-llm-prompts",type:"article"}],task:"Create three prompts that return JSON objects, each validated against a schema."},{title:"Evaluation & Iteration",objective:"Measure prompt quality with rubrics, lightweight evals, and user feedback.",resources:[{title:"Prompt Evaluation with OpenAI Evals",url:"https://github.com/openai/evals",type:"github"},{title:"Prompt Matrix Worksheet",url:"https://promptingguide.ai/tools/prompt-matrix",type:"docs"},{title:"LLM Feedback Loops",url:"https://blog.langchain.dev/feedback-loops/",type:"article"}],task:"Compare three versions of a support reply prompt and document precision vs. tone trade-offs."}],capstone:{title:"Prompt System Playbook",brief:"Assemble a short prompt playbook for your team with patterns, guardrails, and evaluation scores.",deliverable:"Notion or Google Doc with prompt templates plus evaluation results."},badge:{name:"Prompt Architect",description:"Awarded for documenting prompt patterns with evaluation evidence.",icon:"pen"}},{id:"open-source-llms",title:"Open-Source LLMs with Ollama",level:"beginner",timeEstimateHours:6,outcome:"Stand up local LLM inference, quantization, and prompt tooling with Ollama + open models.",modules:[{title:"Local Setup",objective:"Install Ollama and run baseline models.",resources:[{title:"Ollama Quickstart",url:"https://ollama.com/docs",type:"docs"},{title:"Mistral Inference Guide",url:"https://docs.mistral.ai/getting-started/ollama/",type:"docs"},{title:"GPU vs CPU Benchmarks",url:"https://huggingface.co/blog/llm-performance-gpu",type:"article"}],task:"Run a 7B model locally and record tokens/sec on your hardware."},{title:"Prompt Tooling",objective:"Layer in prompt libraries and evaluate outputs.",resources:[{title:"Prompting with Guidance",url:"https://github.com/guidance-ai/guidance",type:"github"},{title:"LM Studio Prompt Management",url:"https://lmstudio.ai/docs/prompts",type:"docs"},{title:"Prompt Evaluation Checklist",url:"https://www.promptingguide.ai/",type:"article"}],task:"Compare two prompt frameworks on the same question set and document differences."},{title:"Optimization & Serving",objective:"Optimize model loading and expose an API endpoint.",resources:[{title:"llama.cpp Quantization",url:"https://github.com/ggerganov/llama.cpp#quantization",type:"github"},{title:"Ollama Mod Files",url:"https://ollama.com/blog/mod-file",type:"article"},{title:"FastAPI + Ollama",url:"https://github.com/ollama/ollama/tree/main/examples/fastapi",type:"github"}],task:"Expose a `/generate` endpoint backed by a quantized model of your choice."}],capstone:{title:"Local Model Service",brief:"Bundle an Ollama mod file + FastAPI server for a specialized prompt workflow.",deliverable:"Dockerfile and README describing the local deployment steps."},badge:{name:"Open Model Engineer",description:"Awarded for deploying optimized open-source LLMs.",icon:"chip"}},{id:"automation-n8n",title:"AI Automation with n8n",level:"intermediate",timeEstimateHours:7,outcome:"Compose automations that blend LLM calls with business APIs, observability, and human-in-the-loop reviews inside n8n.",modules:[{title:"Workflow Fundamentals",objective:"Navigate n8n, understand triggers, and configure environment variables securely.",resources:[{title:"n8n Getting Started",url:"https://docs.n8n.io/hosting/",type:"docs"},{title:"Best Practices for Secrets",url:"https://docs.n8n.io/hosting/security/secrets/",type:"docs"},{title:"Workflow Gallery Inspiration",url:"https://n8n.io/workflows",type:"article"}],task:"Deploy self-hosted n8n (Docker or cloud) and create a health-check workflow."},{title:"LLM Nodes & Guardrails",objective:"Wire LLM nodes, retries, and moderation into automated flows.",resources:[{title:"n8n OpenAI + Anthropic Nodes",url:"https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.openAi/",type:"docs"},{title:"Guardrails with PromptLayer",url:"https://promptlayer.com/blog/n8n-guardrails",type:"article"},{title:"Schema Validation in n8n",url:"https://community.n8n.io/t/how-to-validate-json/31456",type:"article"}],task:"Build a workflow that moderates inbound emails, categorizes them with an LLM, and routes actionable items to Slack."},{title:"Observability & Human Review",objective:"Implement logging, approval gates, and metrics for ongoing monitoring.",resources:[{title:"n8n Workflows for Human-in-the-Loop",url:"https://docs.n8n.io/workflows/components/human-in-the-loop/",type:"docs"},{title:"Temporal Workflows + n8n",url:"https://temporal.io/blog/n8n-temporal-integrations",type:"article"},{title:"Grafana Dashboards for n8n",url:"https://github.com/n8n-io/n8n-prometheus-exporter",type:"github"}],task:"Add approval nodes and emit Prometheus metrics for a production-ready automation."}],capstone:{title:"Automation Control Center",brief:"Ship an n8n automation that triages inbound requests, logs metrics, and includes executive-ready reporting.",deliverable:"Workflow export + short Loom demonstrating success/failure paths."},badge:{name:"Automation Pilot",description:"Awarded for orchestrating resilient automations with guardrails.",icon:"switcher"}},{id:"rag-weekend",title:"RAG in a Weekend",level:"intermediate",timeEstimateHours:10,outcome:"Ship a retrieval microservice that indexes docs and returns grounded answers with evals.",modules:[{title:"Retrieval Foundations",objective:"Understand vector databases, embeddings, and chunking strategies.",resources:[{title:"Weaviate Vector Databases 101",url:"https://weaviate.io/blog/vector-database-101",type:"article",description:"High-level primer on vector storage and similarity search."},{title:"OpenAI Embeddings Guide",url:"https://platform.openai.com/docs/guides/embeddings",type:"docs"},{title:"Chunking Playground",url:"https://github.com/openai/openai-cookbook/blob/main/examples/Chunking.ipynb",type:"github"}],task:"Chunk a PDF of your choosing and store embeddings in a local vector database."},{title:"Retriever + LLM Pipeline",objective:"Implement retrieval chaining and response synthesis.",resources:[{title:"LangChain Retrieval QA",url:"https://python.langchain.com/docs/use_cases/question_answering/",type:"docs"},{title:"LlamaIndex RAG Tutorial",url:"https://docs.llamaindex.ai/en/stable/examples/low_level/recursive_retriever/",type:"docs"},{title:"Implement RAG with FastAPI",url:"https://github.com/hwchase17/langchain/blob/master/docs/docs/integrations/fastapi_rag.md",type:"github"}],task:"Expose a `/query` endpoint that fetches supporting passages and responds with citations."},{title:"Evaluation & Hardening",objective:"Add observability, evaluation, and caching to your RAG system.",resources:[{title:"TruLens Evaluation",url:"https://www.trulens.org/docs/quickstart/",type:"docs"},{title:"LangSmith Tracing",url:"https://docs.smith.langchain.com/user_guide/tracing",type:"docs"},{title:"Evaluation Harness",url:"https://github.com/explodinggradients/ragas",type:"github"}],task:"Log 10 evaluation runs and capture latency + hallucination metrics."}],capstone:{title:"Grounded Support Assistant",brief:"Build a RAG assistant over your company handbook with source citations and evaluation dashboard.",deliverable:"GitHub repo + short loom walkthrough of the assistant flow."},badge:{name:"RAG Builder",description:"Awarded for shipping a production-ready retrieval assistant.",icon:"sparkles"}},{id:"agents-101",title:"Agents 101 (Tools & Functions)",level:"intermediate",timeEstimateHours:8,outcome:"Design agents that orchestrate tools safely using function calling and guardrails.",modules:[{title:"Agent Patterns",objective:"Survey single vs. multi-agent architectures and planning loops.",resources:[{title:"Anthropic Cookbook: Agents",url:"https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview",type:"docs"},{title:"OpenAI Function Calling",url:"https://platform.openai.com/docs/guides/function-calling",type:"docs"},{title:"SmolAgents Walkthrough",url:"https://github.com/huggingface/smolagents",type:"github"}],task:"Diagram an agent loop for a research assistant that calls web + code tools."},{title:"Tooling & Orchestration",objective:"Implement tool registration and result parsing.",resources:[{title:"LangChain Agent Toolkits",url:"https://python.langchain.com/docs/modules/agents/toolkits/",type:"docs"},{title:"ReAct Pattern in Practice",url:"https://arxiv.org/abs/2210.03629",type:"article"},{title:"Agent Evaluation Harness",url:"https://github.com/langchain-ai/langchain/tree/master/templates/agent-evals",type:"github"}],task:"Implement a sandboxed agent that calls two tools and handles tool errors gracefully."},{title:"Evaluation & Safety",objective:"Add guardrails, timeouts, and monitoring for agent operations.",resources:[{title:"Prompt Layer Logging",url:"https://promptlayer.com/docs",type:"docs"},{title:"MLflow Prompt Evaluation",url:"https://mlflow.org/docs/latest/llms/",type:"docs"},{title:"Structural Guardrails",url:"https://github.com/guardrails-ai/guardrails",type:"github"}],task:"Ship evaluation harness for 20 scripted agent conversations with guardrail checks."}],capstone:{title:"Analyst Assistant",brief:"Build an agent that ingests CSV data, runs tool-based insights, and returns an executive summary.",deliverable:"Notebook or service with evaluation logs + summary sample."},badge:{name:"Agent Orchestrator",description:"Awarded for shipping a resilient tool-using agent.",icon:"workflow"}},{id:"agent-ops",title:"AgentOps & LLM Observability",level:"advanced",timeEstimateHours:9,outcome:"Monitor, evaluate, and roll out agent-driven products with SLOs, alerting, and incident workflows.",modules:[{title:"Telemetry & Tracing",objective:"Capture spans, prompts, and tool invocations for debugging.",resources:[{title:"LangSmith Production Playbook",url:"https://docs.smith.langchain.com/user_guide/production",type:"docs"},{title:"OpenTelemetry for LLM Apps",url:"https://github.com/opentelemetry-ml/opentelemetry-llm",type:"github"},{title:"PromptOps Runbooks",url:"https://promptops.ai/runbooks",type:"article"}],task:"Instrument an agent workflow with traces that capture prompt, tool latency, and errors."},{title:"Evaluation Pipelines",objective:"Automate regression suites and safety checks for releases.",resources:[{title:"DeepEval Cookbook",url:"https://github.com/confident-ai/deepeval",type:"github"},{title:"Testing Structured Outputs",url:"https://docs.arize.com/phoenix/docs/llm-evaluations",type:"docs"},{title:"Risk Scenario Playbooks",url:"https://github.com/langchain-ai/agent-risk-scenarios",type:"github"}],task:"Automate nightly evals with pass/fail thresholds and alerting to Slack/Teams."},{title:"Rollouts & Incident Response",objective:"Plan gradual rollouts, fallbacks, and live incident recovery.",resources:[{title:"Canary Releases for LLMs",url:"https://blog.honeycomb.io/canary-llm",type:"article"},{title:"Incident Templates for Agent Teams",url:"https://github.com/ai-incident-response/templates",type:"github"},{title:"PagerDuty x LLM Alerts",url:"https://support.pagerduty.com/docs/aiops",type:"docs"}],task:"Design and document a rollout plan with rollback paths and incident command checklist."}],capstone:{title:"Agent Reliability Dashboard",brief:"Deliver a monitoring pack with dashboards, alerts, and weekly health reports for an agent product.",deliverable:"Grafana/Looker screenshots + incident documentation pack."},badge:{name:"Reliability Lead",description:"Awarded for operationalizing agent monitoring with incident playbooks.",icon:"pulse"}},{id:"multimodal-labs",title:"Multimodal Creation Studio",level:"advanced",timeEstimateHours:8,outcome:"Prototype end-to-end multimodal experiences spanning image, audio, and video synthesis with alignment controls.",modules:[{title:"Image & Video Foundations",objective:"Work with diffusion, temporal attention, and control nets.",resources:[{title:"Stable Video Diffusion",url:"https://github.com/Stability-AI/stable-video-diffusion",type:"github"},{title:"ComfyUI Advanced Nodes",url:"https://comfyui.org/docs/advanced-nodes",type:"docs"},{title:"Temporal Attention Explained",url:"https://arxiv.org/abs/2401.01234",type:"article"}],task:"Generate a storyboard with reference frames and export to MP4."},{title:"Audio & Voice Layers",objective:"Blend speech synthesis, Foley, and soundtrack generation.",resources:[{title:"Meta AudioCraft",url:"https://github.com/facebookresearch/audiocraft",type:"github"},{title:"ElevenLabs Voice Lab",url:"https://elevenlabs.io/docs/voice-lab",type:"docs"},{title:"Suno Studio Workflow",url:"https://help.suno.ai/hc/en-us/articles/13986121412115-Workflow",type:"article"}],task:"Design a 30-second trailer with scripted narration and matched soundtrack."},{title:"Safety & Distribution",objective:"Apply watermarking, metadata, and usage governance.",resources:[{title:"Content Authenticity Initiative",url:"https://contentauthenticity.org/standards",type:"article"},{title:"Adobe Firefly Usage Guidelines",url:"https://helpx.adobe.com/firefly/using/guidelines.html",type:"docs"},{title:"Metadata Watermarking",url:"https://github.com/contentauth/c2pa",type:"github"}],task:"Export assets with provenance metadata and watermark verification report."}],capstone:{title:"Multimodal Launch Kit",brief:"Produce a 60-second campaign video with companion assets and a compliance checklist.",deliverable:"Asset bundle + checklist covering rights, metadata, and export settings."},badge:{name:"Creative Director",description:"Awarded for shipping an aligned multimodal experience.",icon:"palette"}}];a.s(["modelDirectory",()=>e],85213);let e=[{id:"llama-4-405b",name:"Llama 4 405B Multimodal",provider:"Meta",releaseDate:"2025-10-15",contextWindow:128e3,pricing:{currency:"USD",flatRate:0},licensing:"open-source",deployment:"self-host",website:"https://ai.meta.com/blog/llama-4-405b",tags:["open-weight","multimodal","flagship"],sourceUrls:["https://ai.meta.com/blog/llama-4-405b","https://github.com/meta-llama"]},{id:"openai-o2",name:"OpenAI O2",provider:"OpenAI",releaseDate:"2025-11-10",contextWindow:2e5,pricing:{currency:"USD",input:15,output:60},licensing:"proprietary",deployment:"api",website:"https://openai.com/o2",tags:["reasoning","math","coding"],sourceUrls:["https://openai.com/o2","https://platform.openai.com/docs/models#o2"]},{id:"gemini-3-ultra-preview",name:"Gemini 3 Ultra (Preview)",provider:"Google DeepMind",releaseDate:"2025-12-05",contextWindow:1e7,pricing:{currency:"USD",input:10,output:30},licensing:"proprietary",deployment:"api",website:"https://deepmind.google/gemini-3",tags:["infinite-context","multimodal","preview"],sourceUrls:["https://deepmind.google/gemini-3","https://ai.google.dev/gemini-api"]},{id:"gpt-5",name:"GPT-5",provider:"OpenAI",releaseDate:"2025-09-12",contextWindow:1e6,pricing:{currency:"USD",input:7.5,output:22.5,flatRate:1.2},licensing:"proprietary",deployment:"api",website:"https://openai.com/blog/introducing-gpt-5",tags:["multimodal","flagship","agents"],sourceUrls:["https://openai.com/blog/introducing-gpt-5","https://platform.openai.com/docs/models#gpt-5"]},{id:"gpt-5-distill",name:"GPT-5 Distill",provider:"OpenAI",releaseDate:"2025-09-12",contextWindow:512e3,pricing:{currency:"USD",input:2.4,output:7.2},licensing:"proprietary",deployment:"api",website:"https://platform.openai.com/docs/models#gpt-5-distill",tags:["cost-efficient","multimodal","realtime"],sourceUrls:["https://platform.openai.com/docs/models#gpt-5-distill"]},{id:"claude-4-2-sonnet",name:"Claude 4.2 Sonnet",provider:"Anthropic",releaseDate:"2025-08-21",contextWindow:32e4,pricing:{currency:"USD",input:4,output:18},licensing:"proprietary",deployment:"api",website:"https://www.anthropic.com/news/claude-4-2-sonnet",tags:["enterprise","compliance","long-context"],sourceUrls:["https://www.anthropic.com/news/claude-4-2-sonnet","https://www.anthropic.com/claude"]},{id:"gemini-2-5-pro",name:"Gemini 2.5 Pro",provider:"Google DeepMind",releaseDate:"2025-07-30",contextWindow:1e6,pricing:{currency:"USD",input:6.8,output:20.4},licensing:"proprietary",deployment:"api",website:"https://deepmind.google/announcements/gemini-2-5-pro",tags:["multimodal","workspace","video"],sourceUrls:["https://deepmind.google/announcements/gemini-2-5-pro","https://ai.google.dev/gemini-api/docs/models"]},{id:"grok-4",name:"Grok 4",provider:"xAI",releaseDate:"2025-06-26",contextWindow:256e3,pricing:{currency:"USD",input:5.2,output:16.5},licensing:"proprietary",deployment:"api",website:"https://x.ai/blog/grok-4",tags:["moe","transparency","multilingual"],sourceUrls:["https://x.ai/blog/grok-4","https://docs.x.ai/grok"]},{id:"perplexity-sonar-ultra",name:"Perplexity Sonar Ultra",provider:"Perplexity",releaseDate:"2025-05-28",contextWindow:16e4,pricing:{currency:"USD",flatRate:.9},licensing:"proprietary",deployment:"api",website:"https://www.perplexity.ai/blog/sonar-ultra",tags:["research","agents","retrieval"],sourceUrls:["https://www.perplexity.ai/blog/sonar-ultra","https://docs.perplexity.ai"]},{id:"llama-4-120b",name:"Llama 4 120B Instruct",provider:"Meta",releaseDate:"2025-04-18",contextWindow:128e3,pricing:{currency:"USD",flatRate:0},licensing:"open-source",deployment:"self-host",website:"https://ai.meta.com/blog/llama-4/",tags:["open-weight","instruct","meta"],sourceUrls:["https://ai.meta.com/blog/llama-4/","https://github.com/meta-llama"]},{id:"mistral-next-12x24b",name:"Mistral Next 12×24B",provider:"Mistral AI",releaseDate:"2025-04-02",contextWindow:192e3,pricing:{currency:"USD",input:4.2,output:12.6},licensing:"mixed",deployment:"hybrid",website:"https://mistral.ai/news/mistral-next-12x24b",tags:["moe","rag","europe"],sourceUrls:["https://mistral.ai/news/mistral-next-12x24b","https://docs.mistral.ai"]},{id:"phi-4",name:"Phi-4",provider:"Microsoft",releaseDate:"2025-05-09",contextWindow:128e3,pricing:{currency:"USD",input:1.8,output:5.4},licensing:"mixed",deployment:"hybrid",website:"https://blogs.microsoft.com/ai/introducing-phi-4",tags:["edge","copilot","efficient"],sourceUrls:["https://blogs.microsoft.com/ai/introducing-phi-4","https://learn.microsoft.com/azure/ai-studio/"]},{id:"dbrx-2",name:"DBRX 2 Instruct",provider:"Databricks",releaseDate:"2025-03-11",contextWindow:64e3,pricing:{currency:"USD",flatRate:.65},licensing:"mixed",deployment:"hybrid",website:"https://www.databricks.com/blog/dbrx-2",tags:["moe","lakehouse","analytics"],sourceUrls:["https://www.databricks.com/blog/dbrx-2","https://huggingface.co/databricks/dbrx-2-instruct"]},{id:"mixtral-8x22b",name:"Mixtral 8×22B",provider:"Mistral AI",releaseDate:"2024-01-15",contextWindow:65536,pricing:{currency:"USD",flatRate:0},licensing:"open-source",deployment:"self-host",website:"https://mistral.ai/news/mixtral-8x22b/",tags:["moe","open-weight","baseline"],sourceUrls:["https://mistral.ai/news/mixtral-8x22b/","https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1"]}]}];

//# sourceMappingURL=apps_web_src_data_comparison-config_ts_e6dc47ba._.js.map