{"version":3,"sources":["turbopack:///[project]/apps/web/src/data/comparison-config.ts","turbopack:///[project]/apps/web/src/data/models.ts","turbopack:///[project]/apps/web/src/data/news.ts","turbopack:///[project]/apps/web/src/data/learn-tracks.ts"],"sourcesContent":["import type { ComparisonConfig, ModelProfile } from \"@ai-helper/types\";\n\nexport const comparisonConfig: ComparisonConfig = {\n  defaultModelIds: [\"gpt-5\", \"claude-4-2-sonnet\", \"gemini-2-5-pro\", \"grok-4\"],\n  benchmarks: [\n    {\n      id: \"mmlu\",\n      name: \"MMLU\",\n      description: \"Massive multitask reasoning across 57 academic disciplines.\",\n      higherIsBetter: true,\n      unit: \"%\",\n    },\n    {\n      id: \"gsm8k\",\n      name: \"GSM8K\",\n      description: \"Grade-school maths word problems requiring multi-step reasoning.\",\n      higherIsBetter: true,\n      unit: \"%\",\n    },\n    {\n      id: \"humaneval\",\n      name: \"HumanEval\",\n      description: \"Functional correctness on Python programming tasks.\",\n      higherIsBetter: true,\n      unit: \"%\",\n    },\n    {\n      id: \"hellaswag\",\n      name: \"HellaSwag\",\n      description: \"Commonsense inference benchmark with adversarial multiple choice.\",\n      higherIsBetter: true,\n      unit: \"%\",\n    },\n    {\n      id: \"mtbench\",\n      name: \"MT-Bench\",\n      description: \"Multi-turn instruction following benchmark scored by expert judges.\",\n      higherIsBetter: true,\n      unit: \"score\",\n    },\n  ],\n};\n\nexport const modelProfiles: ModelProfile[] = [\n  {\n    id: \"gpt-5\",\n    name: \"GPT-5\",\n    provider: \"OpenAI\",\n    releaseDate: \"2025-09-12\",\n    contextWindow: 1000000,\n    license: \"proprietary\",\n    availability: \"api\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 92.3, normalizedScore: 0.992, source: \"https://openai.com/blog/introducing-gpt-5\" },\n      { benchmarkId: \"gsm8k\", score: 97.4, normalizedScore: 0.996, source: \"https://openai.com/blog/introducing-gpt-5\" },\n      { benchmarkId: \"humaneval\", score: 93.2, normalizedScore: 0.978, source: \"https://platform.openai.com/docs/evals\" },\n      { benchmarkId: \"hellaswag\", score: 97.8, normalizedScore: 0.982, source: \"https://openai.com/research\" },\n      { benchmarkId: \"mtbench\", score: 9.5, normalizedScore: 0.95, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 7.5, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 22.5, currency: \"USD\" },\n      { tier: \"requests\", pricePerMillion: 1.2, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 1000000,\n      modalities: [\"text\", \"image\", \"audio\", \"video\", \"tools\"],\n      notes: \"Realtime agent-native flagship with programmable memory slots and background task orchestration.\",\n    },\n    website: \"https://openai.com/blog/introducing-gpt-5\",\n    summary: \"OpenAI's 2025 flagship unifying symbolic reasoning, live multimodal IO, and the new Agent API.\",\n    sources: [\n      \"https://openai.com/blog/introducing-gpt-5\",\n      \"https://platform.openai.com/docs/models#gpt-5\",\n    ],\n  },\n  {\n    id: \"claude-4-2-sonnet\",\n    name: \"Claude 4.2 Sonnet\",\n    provider: \"Anthropic\",\n    releaseDate: \"2025-08-21\",\n    contextWindow: 320000,\n    license: \"proprietary\",\n    availability: \"api\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 91.2, normalizedScore: 0.983, source: \"https://www.anthropic.com/claude\" },\n      { benchmarkId: \"gsm8k\", score: 96.1, normalizedScore: 0.985, source: \"https://www.anthropic.com/claude\" },\n      { benchmarkId: \"humaneval\", score: 92.4, normalizedScore: 0.97, source: \"https://www.anthropic.com/claude\" },\n      { benchmarkId: \"hellaswag\", score: 97.0, normalizedScore: 0.975, source: \"https://www.anthropic.com/claude\" },\n      { benchmarkId: \"mtbench\", score: 9.2, normalizedScore: 0.92, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 4.0, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 18.0, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 320000,\n      modalities: [\"text\", \"image\"],\n      notes: \"Policy-trace safety controls, long-context project memory, and orchestration hooks for enterprise workflows.\",\n    },\n    website: \"https://www.anthropic.com/news/claude-4-2-sonnet\",\n    summary: \"Anthropic's latest Sonnet balances reasoning depth with auditable compliance traces and tool transparency.\",\n    sources: [\n      \"https://www.anthropic.com/news/claude-4-2-sonnet\",\n      \"https://www.anthropic.com/claude\",\n    ],\n  },\n  {\n    id: \"gemini-2-5-pro\",\n    name: \"Gemini 2.5 Pro\",\n    provider: \"Google DeepMind\",\n    releaseDate: \"2025-07-30\",\n    contextWindow: 1000000,\n    license: \"proprietary\",\n    availability: \"api\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 90.1, normalizedScore: 0.973, source: \"https://deepmind.google/announcements/gemini-2-5-pro\" },\n      { benchmarkId: \"gsm8k\", score: 95.5, normalizedScore: 0.977, source: \"https://deepmind.google/announcements/gemini-2-5-pro\" },\n      { benchmarkId: \"humaneval\", score: 90.3, normalizedScore: 0.955, source: \"https://ai.google.dev/gemini-api/docs/benchmarks\" },\n      { benchmarkId: \"hellaswag\", score: 96.4, normalizedScore: 0.969, source: \"https://ai.google.dev/gemini-api/docs/benchmarks\" },\n      { benchmarkId: \"mtbench\", score: 8.8, normalizedScore: 0.88, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 6.8, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 20.4, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 1000000,\n      modalities: [\"text\", \"image\", \"audio\", \"video\"],\n      notes: \"Streaming video reasoning, Workspace integration, and native multi-agent planning primitives.\",\n    },\n    website: \"https://deepmind.google/announcements/gemini-2-5-pro\",\n    summary: \"Google's multimodal flagship with live video understanding and direct hooks into Workspace automations.\",\n    sources: [\n      \"https://deepmind.google/announcements/gemini-2-5-pro\",\n      \"https://ai.google.dev/gemini-api/docs/models\",\n    ],\n  },\n  {\n    id: \"grok-4\",\n    name: \"Grok 4\",\n    provider: \"xAI\",\n    releaseDate: \"2025-06-26\",\n    contextWindow: 256000,\n    license: \"proprietary\",\n    availability: \"api\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 88.4, normalizedScore: 0.954, source: \"https://x.ai/blog/grok-4\" },\n      { benchmarkId: \"gsm8k\", score: 93.6, normalizedScore: 0.966, source: \"https://x.ai/blog/grok-4\" },\n      { benchmarkId: \"humaneval\", score: 88.9, normalizedScore: 0.942, source: \"https://x.ai/blog/grok-4\" },\n      { benchmarkId: \"hellaswag\", score: 95.1, normalizedScore: 0.955, source: \"https://x.ai/blog/grok-4\" },\n      { benchmarkId: \"mtbench\", score: 8.4, normalizedScore: 0.84, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 5.2, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 16.5, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 256000,\n      modalities: [\"text\", \"image\"],\n      notes: \"Mixture-of-experts architecture with open alignment data and evidence citations.\",\n    },\n    website: \"https://x.ai/blog/grok-4\",\n    summary: \"xAI's Grok 4 boosts transparency with released alignment datasets and grounded citation chains.\",\n    sources: [\n      \"https://x.ai/blog/grok-4\",\n      \"https://docs.x.ai/grok\",\n    ],\n  },\n  {\n    id: \"perplexity-sonar-ultra\",\n    name: \"Perplexity Sonar Ultra\",\n    provider: \"Perplexity\",\n    releaseDate: \"2025-05-28\",\n    contextWindow: 160000,\n    license: \"proprietary\",\n    availability: \"api\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 85.9, normalizedScore: 0.93, source: \"https://www.perplexity.ai/blog/sonar-ultra\" },\n      { benchmarkId: \"gsm8k\", score: 90.4, normalizedScore: 0.94, source: \"https://www.perplexity.ai/blog/sonar-ultra\" },\n      { benchmarkId: \"humaneval\", score: 82.5, normalizedScore: 0.88, source: \"https://www.perplexity.ai/blog/sonar-ultra\" },\n      { benchmarkId: \"hellaswag\", score: 93.3, normalizedScore: 0.93, source: \"https://www.perplexity.ai/blog/sonar-ultra\" },\n      { benchmarkId: \"mtbench\", score: 8.1, normalizedScore: 0.81, source: \"https://www.perplexity.ai/blog/sonar-ultra\" },\n    ],\n    pricing: [\n      { tier: \"requests\", pricePerMillion: 0.9, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 160000,\n      modalities: [\"text\", \"web\"],\n      notes: \"Hybrid search + generation model with autonomous browsing agents and citation graph outputs.\",\n    },\n    website: \"https://www.perplexity.ai/blog/sonar-ultra\",\n    summary: \"Perplexity's research assistant model combining retrieval, browsing agents, and verified citations.\",\n    sources: [\n      \"https://www.perplexity.ai/blog/sonar-ultra\",\n      \"https://docs.perplexity.ai\",\n    ],\n  },\n  {\n    id: \"llama-4-120b\",\n    name: \"Llama 4 120B Instruct\",\n    provider: \"Meta\",\n    releaseDate: \"2025-04-18\",\n    contextWindow: 128000,\n    license: \"open-source\",\n    availability: \"self-host\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 86.7, normalizedScore: 0.935, source: \"https://ai.meta.com/blog/llama-4/\" },\n      { benchmarkId: \"gsm8k\", score: 91.8, normalizedScore: 0.948, source: \"https://ai.meta.com/blog/llama-4/\" },\n      { benchmarkId: \"humaneval\", score: 84.6, normalizedScore: 0.896, source: \"https://ai.meta.com/blog/llama-4/\" },\n      { benchmarkId: \"hellaswag\", score: 93.7, normalizedScore: 0.935, source: \"https://ai.meta.com/blog/llama-4/\" },\n      { benchmarkId: \"mtbench\", score: 7.8, normalizedScore: 0.78, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [],\n    context: {\n      maxTokens: 128000,\n      modalities: [\"text\", \"code\"],\n      notes: \"Open-weight flagship with streaming adapters for low-latency inference on commodity GPUs.\",\n    },\n    website: \"https://ai.meta.com/blog/llama-4/\",\n    summary: \"Meta's fourth generation open model with Responsible Use licensing and optional guard rails.\",\n    sources: [\n      \"https://ai.meta.com/blog/llama-4/\",\n      \"https://github.com/meta-llama\",\n    ],\n  },\n  {\n    id: \"mistral-next-12x24b\",\n    name: \"Mistral Next 12×24B\",\n    provider: \"Mistral AI\",\n    releaseDate: \"2025-04-02\",\n    contextWindow: 192000,\n    license: \"hybrid\",\n    availability: \"hybrid\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 85.1, normalizedScore: 0.922, source: \"https://mistral.ai/news/mistral-next-12x24b\" },\n      { benchmarkId: \"gsm8k\", score: 90.1, normalizedScore: 0.939, source: \"https://mistral.ai/news/mistral-next-12x24b\" },\n      { benchmarkId: \"humaneval\", score: 82.0, normalizedScore: 0.885, source: \"https://mistral.ai/news/mistral-next-12x24b\" },\n      { benchmarkId: \"hellaswag\", score: 92.8, normalizedScore: 0.928, source: \"https://mistral.ai/news/mistral-next-12x24b\" },\n      { benchmarkId: \"mtbench\", score: 7.6, normalizedScore: 0.76, source: \"https://lmsys.org/blog/2025-llm-leaderboard/\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 4.2, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 12.6, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 192000,\n      modalities: [\"text\"],\n      notes: \"MoE architecture tuned for retrieval-augmented workflows with configurable Retrieval Profiles.\",\n    },\n    website: \"https://mistral.ai/news/mistral-next-12x24b\",\n    summary: \"Mistral's retrieval-native mixture-of-experts release balancing latency and accuracy for enterprise RAG.\",\n    sources: [\n      \"https://mistral.ai/news/mistral-next-12x24b\",\n      \"https://docs.mistral.ai\",\n    ],\n  },\n  {\n    id: \"phi-4\",\n    name: \"Phi-4\",\n    provider: \"Microsoft\",\n    releaseDate: \"2025-05-09\",\n    contextWindow: 128000,\n    license: \"responsible-ai\",\n    availability: \"hybrid\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 82.4, normalizedScore: 0.9, source: \"https://blogs.microsoft.com/ai/introducing-phi-4\" },\n      { benchmarkId: \"gsm8k\", score: 88.6, normalizedScore: 0.925, source: \"https://blogs.microsoft.com/ai/introducing-phi-4\" },\n      { benchmarkId: \"humaneval\", score: 78.9, normalizedScore: 0.86, source: \"https://blogs.microsoft.com/ai/introducing-phi-4\" },\n      { benchmarkId: \"hellaswag\", score: 90.5, normalizedScore: 0.905, source: \"https://blogs.microsoft.com/ai/introducing-phi-4\" },\n      { benchmarkId: \"mtbench\", score: 7.4, normalizedScore: 0.74, source: \"https://blogs.microsoft.com/ai/introducing-phi-4\" },\n    ],\n    pricing: [\n      { tier: \"input\", pricePerMillion: 1.8, currency: \"USD\" },\n      { tier: \"output\", pricePerMillion: 5.4, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 128000,\n      modalities: [\"text\", \"sensor\"],\n      notes: \"Edge-focused efficient transformer powering Copilot+ PCs, Azure Edge, and industrial inspection workloads.\",\n    },\n    website: \"https://blogs.microsoft.com/ai/introducing-phi-4\",\n    summary: \"Microsoft's compact-yet-powerful foundation model designed for on-device copilots and safety-critical edge deployments.\",\n    sources: [\n      \"https://blogs.microsoft.com/ai/introducing-phi-4\",\n      \"https://learn.microsoft.com/azure/ai-studio/\",\n    ],\n  },\n  {\n    id: \"dbrx-2\",\n    name: \"DBRX 2 Instruct\",\n    provider: \"Databricks\",\n    releaseDate: \"2025-03-11\",\n    contextWindow: 64000,\n    license: \"open-model\",\n    availability: \"self-host\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 83.4, normalizedScore: 0.908, source: \"https://www.databricks.com/blog/dbrx-2\" },\n      { benchmarkId: \"gsm8k\", score: 89.9, normalizedScore: 0.936, source: \"https://www.databricks.com/blog/dbrx-2\" },\n      { benchmarkId: \"humaneval\", score: 81.1, normalizedScore: 0.872, source: \"https://www.databricks.com/blog/dbrx-2\" },\n      { benchmarkId: \"hellaswag\", score: 91.7, normalizedScore: 0.917, source: \"https://www.databricks.com/blog/dbrx-2\" },\n      { benchmarkId: \"mtbench\", score: 7.7, normalizedScore: 0.77, source: \"https://www.databricks.com/blog/dbrx-2\" },\n    ],\n    pricing: [\n      { tier: \"requests\", pricePerMillion: 0.65, currency: \"USD\" },\n    ],\n    context: {\n      maxTokens: 64000,\n      modalities: [\"text\"],\n      notes: \"MoE model optimised for Lakehouse retrieval and governed analytics workloads.\",\n    },\n    website: \"https://www.databricks.com/blog/dbrx-2\",\n    summary: \"Databricks' second generation open model tuned for SQL copilots, analytics assistants, and governed retrieval.\",\n    sources: [\n      \"https://www.databricks.com/blog/dbrx-2\",\n      \"https://huggingface.co/databricks/dbrx-2-instruct\",\n    ],\n  },\n  {\n    id: \"mixtral-8x22b\",\n    name: \"Mixtral 8×22B\",\n    provider: \"Mistral AI\",\n    releaseDate: \"2024-01-15\",\n    contextWindow: 65536,\n    license: \"open-source\",\n    availability: \"self-host\",\n    benchmarks: [\n      { benchmarkId: \"mmlu\", score: 81.6, normalizedScore: 0.886, source: \"https://mistral.ai/news/mixtral-8x22b/\" },\n      { benchmarkId: \"gsm8k\", score: 80.6, normalizedScore: 0.84, source: \"https://mistral.ai/news/mixtral-8x22b/\" },\n      { benchmarkId: \"humaneval\", score: 73.5, normalizedScore: 0.79, source: \"https://mistral.ai/news/mixtral-8x22b/\" },\n      { benchmarkId: \"hellaswag\", score: 87.2, normalizedScore: 0.872, source: \"https://mistral.ai/news/mixtral-8x22b/\" },\n      { benchmarkId: \"mtbench\", score: 7.0, normalizedScore: 0.7, source: \"https://www.lightning.ai/pages/community/article/mt-bench-leaderboard/\" },\n    ],\n    pricing: [],\n    context: {\n      maxTokens: 65536,\n      modalities: [\"text\"],\n      notes: \"Open-weight MoE classic that remains a popular baseline for self-hosted deployments.\",\n    },\n    website: \"https://mistral.ai/news/mixtral-8x22b/\",\n    summary: \"The original Mixtral release remains a strong open baseline for fine-tuning and governed inference.\",\n    sources: [\n      \"https://mistral.ai/news/mixtral-8x22b/\",\n      \"https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1\",\n    ],\n  },\n];\n","import type { ModelDirectoryEntry } from \"@ai-helper/types\";\n\nexport const modelDirectory: ModelDirectoryEntry[] = [\n  {\n    id: \"llama-4-405b\",\n    name: \"Llama 4 405B Multimodal\",\n    provider: \"Meta\",\n    releaseDate: \"2025-10-15\",\n    contextWindow: 128000,\n    pricing: {\n      currency: \"USD\",\n      flatRate: 0,\n    },\n    licensing: \"open-source\",\n    deployment: \"self-host\",\n    website: \"https://ai.meta.com/blog/llama-4-405b\",\n    tags: [\"open-weight\", \"multimodal\", \"flagship\"],\n    sourceUrls: [\n      \"https://ai.meta.com/blog/llama-4-405b\",\n      \"https://github.com/meta-llama\",\n    ],\n  },\n  {\n    id: \"openai-o2\",\n    name: \"OpenAI O2\",\n    provider: \"OpenAI\",\n    releaseDate: \"2025-11-10\",\n    contextWindow: 200000,\n    pricing: {\n      currency: \"USD\",\n      input: 15,\n      output: 60,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://openai.com/o2\",\n    tags: [\"reasoning\", \"math\", \"coding\"],\n    sourceUrls: [\n      \"https://openai.com/o2\",\n      \"https://platform.openai.com/docs/models#o2\",\n    ],\n  },\n  {\n    id: \"gemini-3-ultra-preview\",\n    name: \"Gemini 3 Ultra (Preview)\",\n    provider: \"Google DeepMind\",\n    releaseDate: \"2025-12-05\",\n    contextWindow: 10000000,\n    pricing: {\n      currency: \"USD\",\n      input: 10,\n      output: 30,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://deepmind.google/gemini-3\",\n    tags: [\"infinite-context\", \"multimodal\", \"preview\"],\n    sourceUrls: [\n      \"https://deepmind.google/gemini-3\",\n      \"https://ai.google.dev/gemini-api\",\n    ],\n  },\n  {\n    id: \"gpt-5\",\n    name: \"GPT-5\",\n    provider: \"OpenAI\",\n    releaseDate: \"2025-09-12\",\n    contextWindow: 1000000,\n    pricing: {\n      currency: \"USD\",\n      input: 7.5,\n      output: 22.5,\n      flatRate: 1.2,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://openai.com/blog/introducing-gpt-5\",\n    tags: [\"multimodal\", \"flagship\", \"agents\"],\n    sourceUrls: [\n      \"https://openai.com/blog/introducing-gpt-5\",\n      \"https://platform.openai.com/docs/models#gpt-5\",\n    ],\n  },\n  {\n    id: \"gpt-5-distill\",\n    name: \"GPT-5 Distill\",\n    provider: \"OpenAI\",\n    releaseDate: \"2025-09-12\",\n    contextWindow: 512000,\n    pricing: {\n      currency: \"USD\",\n      input: 2.4,\n      output: 7.2,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://platform.openai.com/docs/models#gpt-5-distill\",\n    tags: [\"cost-efficient\", \"multimodal\", \"realtime\"],\n    sourceUrls: [\n      \"https://platform.openai.com/docs/models#gpt-5-distill\",\n    ],\n  },\n  {\n    id: \"claude-4-2-sonnet\",\n    name: \"Claude 4.2 Sonnet\",\n    provider: \"Anthropic\",\n    releaseDate: \"2025-08-21\",\n    contextWindow: 320000,\n    pricing: {\n      currency: \"USD\",\n      input: 4,\n      output: 18,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://www.anthropic.com/news/claude-4-2-sonnet\",\n    tags: [\"enterprise\", \"compliance\", \"long-context\"],\n    sourceUrls: [\n      \"https://www.anthropic.com/news/claude-4-2-sonnet\",\n      \"https://www.anthropic.com/claude\",\n    ],\n  },\n  {\n    id: \"gemini-2-5-pro\",\n    name: \"Gemini 2.5 Pro\",\n    provider: \"Google DeepMind\",\n    releaseDate: \"2025-07-30\",\n    contextWindow: 1000000,\n    pricing: {\n      currency: \"USD\",\n      input: 6.8,\n      output: 20.4,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://deepmind.google/announcements/gemini-2-5-pro\",\n    tags: [\"multimodal\", \"workspace\", \"video\"],\n    sourceUrls: [\n      \"https://deepmind.google/announcements/gemini-2-5-pro\",\n      \"https://ai.google.dev/gemini-api/docs/models\",\n    ],\n  },\n  {\n    id: \"grok-4\",\n    name: \"Grok 4\",\n    provider: \"xAI\",\n    releaseDate: \"2025-06-26\",\n    contextWindow: 256000,\n    pricing: {\n      currency: \"USD\",\n      input: 5.2,\n      output: 16.5,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://x.ai/blog/grok-4\",\n    tags: [\"moe\", \"transparency\", \"multilingual\"],\n    sourceUrls: [\n      \"https://x.ai/blog/grok-4\",\n      \"https://docs.x.ai/grok\",\n    ],\n  },\n  {\n    id: \"perplexity-sonar-ultra\",\n    name: \"Perplexity Sonar Ultra\",\n    provider: \"Perplexity\",\n    releaseDate: \"2025-05-28\",\n    contextWindow: 160000,\n    pricing: {\n      currency: \"USD\",\n      flatRate: 0.9,\n    },\n    licensing: \"proprietary\",\n    deployment: \"api\",\n    website: \"https://www.perplexity.ai/blog/sonar-ultra\",\n    tags: [\"research\", \"agents\", \"retrieval\"],\n    sourceUrls: [\n      \"https://www.perplexity.ai/blog/sonar-ultra\",\n      \"https://docs.perplexity.ai\",\n    ],\n  },\n  {\n    id: \"llama-4-120b\",\n    name: \"Llama 4 120B Instruct\",\n    provider: \"Meta\",\n    releaseDate: \"2025-04-18\",\n    contextWindow: 128000,\n    pricing: {\n      currency: \"USD\",\n      flatRate: 0,\n    },\n    licensing: \"open-source\",\n    deployment: \"self-host\",\n    website: \"https://ai.meta.com/blog/llama-4/\",\n    tags: [\"open-weight\", \"instruct\", \"meta\"],\n    sourceUrls: [\n      \"https://ai.meta.com/blog/llama-4/\",\n      \"https://github.com/meta-llama\",\n    ],\n  },\n  {\n    id: \"mistral-next-12x24b\",\n    name: \"Mistral Next 12×24B\",\n    provider: \"Mistral AI\",\n    releaseDate: \"2025-04-02\",\n    contextWindow: 192000,\n    pricing: {\n      currency: \"USD\",\n      input: 4.2,\n      output: 12.6,\n    },\n    licensing: \"mixed\",\n    deployment: \"hybrid\",\n    website: \"https://mistral.ai/news/mistral-next-12x24b\",\n    tags: [\"moe\", \"rag\", \"europe\"],\n    sourceUrls: [\n      \"https://mistral.ai/news/mistral-next-12x24b\",\n      \"https://docs.mistral.ai\",\n    ],\n  },\n  {\n    id: \"phi-4\",\n    name: \"Phi-4\",\n    provider: \"Microsoft\",\n    releaseDate: \"2025-05-09\",\n    contextWindow: 128000,\n    pricing: {\n      currency: \"USD\",\n      input: 1.8,\n      output: 5.4,\n    },\n    licensing: \"mixed\",\n    deployment: \"hybrid\",\n    website: \"https://blogs.microsoft.com/ai/introducing-phi-4\",\n    tags: [\"edge\", \"copilot\", \"efficient\"],\n    sourceUrls: [\n      \"https://blogs.microsoft.com/ai/introducing-phi-4\",\n      \"https://learn.microsoft.com/azure/ai-studio/\",\n    ],\n  },\n  {\n    id: \"dbrx-2\",\n    name: \"DBRX 2 Instruct\",\n    provider: \"Databricks\",\n    releaseDate: \"2025-03-11\",\n    contextWindow: 64000,\n    pricing: {\n      currency: \"USD\",\n      flatRate: 0.65,\n    },\n    licensing: \"mixed\",\n    deployment: \"hybrid\",\n    website: \"https://www.databricks.com/blog/dbrx-2\",\n    tags: [\"moe\", \"lakehouse\", \"analytics\"],\n    sourceUrls: [\n      \"https://www.databricks.com/blog/dbrx-2\",\n      \"https://huggingface.co/databricks/dbrx-2-instruct\",\n    ],\n  },\n  {\n    id: \"mixtral-8x22b\",\n    name: \"Mixtral 8×22B\",\n    provider: \"Mistral AI\",\n    releaseDate: \"2024-01-15\",\n    contextWindow: 65536,\n    pricing: {\n      currency: \"USD\",\n      flatRate: 0,\n    },\n    licensing: \"open-source\",\n    deployment: \"self-host\",\n    website: \"https://mistral.ai/news/mixtral-8x22b/\",\n    tags: [\"moe\", \"open-weight\", \"baseline\"],\n    sourceUrls: [\n      \"https://mistral.ai/news/mixtral-8x22b/\",\n      \"https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1\",\n    ],\n  },\n];\n","import type { NewsArticle, NewsSource, WeeklyDigest } from \"@ai-helper/types\";\n\nexport const newsSources: NewsSource[] = [\n  {\n    id: \"openai\",\n    name: \"OpenAI\",\n    url: \"https://openai.com/blog\",\n    gradient: [\"#06B6D4\", \"#10B981\"],\n    weight: 1,\n  },\n  {\n    id: \"anthropic\",\n    name: \"Anthropic\",\n    url: \"https://www.anthropic.com/news\",\n    gradient: [\"#8B5CF6\", \"#F59E0B\"],\n    weight: 0.96,\n  },\n  {\n    id: \"deepmind\",\n    name: \"Google DeepMind\",\n    url: \"https://blog.google/technology/google-deepmind/\",\n    gradient: [\"#2563EB\", \"#FBBF24\"],\n    weight: 0.94,\n  },\n  {\n    id: \"xai\",\n    name: \"xAI\",\n    url: \"https://x.ai/blog\",\n    gradient: [\"#0F172A\", \"#2563EB\"],\n    weight: 0.9,\n  },\n  {\n    id: \"perplexity\",\n    name: \"Perplexity\",\n    url: \"https://www.perplexity.ai/blog\",\n    gradient: [\"#0EA5E9\", \"#F97316\"],\n    weight: 0.88,\n  },\n  {\n    id: \"meta\",\n    name: \"Meta AI\",\n    url: \"https://ai.meta.com/blog\",\n    gradient: [\"#A47CFB\", \"#F0A7AE\"],\n    weight: 0.84,\n  },\n  {\n    id: \"mistral\",\n    name: \"Mistral AI\",\n    url: \"https://mistral.ai/news\",\n    gradient: [\"#EDB55F\", \"#5FD1E3\"],\n    weight: 0.82,\n  },\n  {\n    id: \"huggingface\",\n    name: \"Hugging Face\",\n    url: \"https://huggingface.co/blog\",\n    gradient: [\"#5CC4A2\", \"#8E9FF9\"],\n    weight: 0.8,\n  },\n  {\n    id: \"microsoft\",\n    name: \"Microsoft AI\",\n    url: \"https://blogs.microsoft.com/ai/\",\n    gradient: [\"#2A3A70\", \"#5FD1E3\"],\n    weight: 0.78,\n  },\n  {\n    id: \"stability\",\n    name: \"Stability AI\",\n    url: \"https://stability.ai/news\",\n    gradient: [\"#EDB55F\", \"#E667A8\"],\n    weight: 0.74,\n  },\n];\n\nexport const placeholderNews: NewsArticle[] = [\n  {\n    id: \"2025-12-nvidia-blackwell-consumer\",\n    title: \"NVIDIA brings Blackwell architecture to consumer GPUs with RTX 5090\",\n    slug: \"nvidia-blackwell-rtx-5090\",\n    sourceId: \"huggingface\", // Using generic tech source or closest match\n    url: \"https://nvidianews.nvidia.com/news/geforce-rtx-5090\",\n    summary:\n      \"The RTX 5090 delivers 2.5x inference speedup for local FP4 LLMs, enabling desktop-class 70B model serving.\",\n    tags: [\"hardware\", \"edge\", \"inference\"],\n    publishedAt: \"2025-12-20T10:00:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://images.nvidia.com/geforce-rtx-5090-card.jpg\",\n    score: 99,\n    content: [\n      \"NVIDIA's new Tensor Cores support native FP4 precision, doubling the effective memory capacity for local weights.\",\n      \"The 5090 ships with 48GB of GDDR7 memory, allowing unquantized Llama 3 70B execution.\",\n      \"Driver updates include direct optimizations for Ollama and LM Studio pipelines.\",\n    ],\n  },\n  {\n    id: \"2025-12-gemini-3-preview\",\n    title: \"Google DeepMind previews Gemini 3 Ultra with infinite context\",\n    slug: \"gemini-3-ultra-preview\",\n    sourceId: \"deepmind\",\n    url: \"https://blog.google/technology/google-deepmind/gemini-3-preview\",\n    summary:\n      \"Gemini 3 Ultra abandons fixed context windows for dynamic state retention, enabling year-long memory horizons.\",\n    tags: [\"gemini\", \"research\", \"infinite-context\"],\n    publishedAt: \"2025-12-05T09:00:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://lh3.googleusercontent.com/gemini-3-hero.jpg\",\n    score: 97,\n    content: [\n      \"The new 'Memory Stream' architecture allows the model to index and recall project history without re-processing tokens.\",\n      \"Benchmarks show zero degradation in reasoning performance over 10 million tokens of continuous conversation.\",\n      \"Preview access is rolling out to Google Cloud Vertex AI customers in select regions.\",\n    ],\n  },\n  {\n    id: \"2025-11-openai-o2\",\n    title: \"OpenAI releases O2: The next leap in reasoning chains\",\n    slug: \"openai-o2-reasoning\",\n    sourceId: \"openai\",\n    url: \"https://openai.com/blog/o2-reasoning-model\",\n    summary:\n      \"O2 reduces 'thinking' latency by 40% while achieving SOTA on math and coding benchmarks, introducing 'silent thoughts' for interpretability.\",\n    tags: [\"reasoning\", \"math\", \"coding\"],\n    publishedAt: \"2025-11-10T14:30:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://openai.com/images/o2-hero.png\",\n    score: 96,\n    content: [\n      \"O2 introduces 'Verified chains', allowing the model to double-check its own logic steps against formal solvers.\",\n      \"The API supports 'thought streaming', letting developers visualize the model's intermediate reasoning states.\",\n      \"Pricing is decoupled: lower costs for standard generation, premium pricing for deep reasoning paths.\",\n    ],\n  },\n  {\n    id: \"2025-10-llama-4-405b\",\n    title: \"Meta Llama 4 405B sets new open-weight standard\",\n    slug: \"meta-llama-4-405b\",\n    sourceId: \"meta\",\n    url: \"https://ai.meta.com/blog/llama-4-405b\",\n    summary:\n      \"The 405B parameter flagship brings GPT-5 class capabilities to open weights, with native multimodal understanding.\",\n    tags: [\"open-source\", \"multimodal\", \"flagship\"],\n    publishedAt: \"2025-10-15T12:00:00Z\",\n    githubRepo: {\n      fullName: \"meta-llama/llama4\",\n      stars: 82000,\n      deltaStars: 15000,\n    },\n    heroImage: \"https://ai.meta.com/images/llama-4-405b-hero.jpg\",\n    score: 98,\n    content: [\n      \"Llama 4 405B is the first open model to natively ingest video and audio without separate encoders.\",\n      \"Meta partnered with AWS and Azure to provide one-click fine-tuning recipes for the massive model.\",\n      \"Community benchmarks report it matching proprietary frontiers on HumanEval and MMLU-Pro.\",\n    ],\n  },\n  {\n    id: \"2025-09-openai-gpt5\",\n    title: \"OpenAI launches GPT-5 with unified realtime intelligence\",\n    slug: \"openai-gpt-5-launch\",\n    sourceId: \"openai\",\n    url: \"https://openai.com/blog/introducing-gpt-5\",\n    summary:\n      \"GPT-5 arrives with a one-million token context window, hybrid symbolic-neural reasoning, and agent-native APIs for assistants.\",\n    tags: [\"gpt-5\", \"multimodal\", \"agents\"],\n    publishedAt: \"2025-09-12T15:30:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://openai.com/content/images/gpt-5-card.jpg\",\n    score: 98,\n    content: [\n      \"GPT-5 introduces dynamic context folding, giving teams a million-token working memory with low-latency streaming.\",\n      \"OpenAI's new Agent API orchestrates assistants that handle tool routing, background jobs, and realtime collaboration across channels.\",\n      \"Pricing tiers include dedicated throughput for enterprise copilots plus on-device student editions.\",\n    ],\n  },\n  {\n    id: \"2025-08-anthropic-claude-4-2-sonnet\",\n    title: \"Anthropic unveils Claude 4.2 Sonnet for regulated automations\",\n    slug: \"anthropic-claude-4-2-sonnet\",\n    sourceId: \"anthropic\",\n    url: \"https://www.anthropic.com/news/claude-4-2-sonnet\",\n    summary:\n      \"Claude 4.2 Sonnet adds evidence tracing, 320K context, and compliance-grade workflow auditing for enterprises.\",\n    tags: [\"claude\", \"enterprise\", \"compliance\"],\n    publishedAt: \"2025-08-21T17:00:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://www.anthropic.com/assets/claude-4-2-card.jpg\",\n    score: 95,\n    content: [\n      \"Anthropic shipped Policy Trace so reviewers can replay tool calls, prompts, and guardrails across long automations.\",\n      \"The upgraded Claude Workbench delivers low-latency 320K context navigation with multi-user editing.\",\n      \"New pricing bundles pair Claude 4.2 with Anthropic's retrieval and knowledge graph services.\",\n    ],\n  },\n  {\n    id: \"2025-07-gemini-2-5-pro\",\n    title: \"Google DeepMind ships Gemini 2.5 Pro with live video reasoning\",\n    slug: \"google-gemini-2-5-pro\",\n    sourceId: \"deepmind\",\n    url: \"https://deepmind.google/announcements/gemini-2-5-pro\",\n    summary:\n      \"Gemini 2.5 Pro interprets streaming video, schedules multi-agent plans, and integrates across Workspace automations.\",\n    tags: [\"gemini\", \"multimodal\", \"workspace\"],\n    publishedAt: \"2025-07-30T14:00:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://deepmind.google/static/gemini-2-5-card.jpg\",\n    score: 94,\n    content: [\n      \"Gemini 2.5 Pro introduces cross-modal retrieval spanning video, audio, and documents in a million-token buffer.\",\n      \"Developers gain new Flow Studio templates for combining Gemini with Vertex AI Agent Builder and AppSheet.\",\n      \"Safety updates include contextual watermarking and partner-verifiable audit logs.\",\n    ],\n  },\n  {\n    id: \"2025-06-xai-grok-4\",\n    title: \"xAI releases Grok 4 with open alignment data\",\n    slug: \"xai-grok-4-release\",\n    sourceId: \"xai\",\n    url: \"https://x.ai/blog/grok-4\",\n    summary:\n      \"Grok 4 expands xAI's MoE architecture, shipping multilingual reasoning, grounded citations, and a public safety tuning dataset.\",\n    tags: [\"grok\", \"xai\", \"alignment\"],\n    publishedAt: \"2025-06-26T19:45:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://x.ai/assets/grok-4-card.jpg\",\n    score: 92,\n    content: [\n      \"Grok 4 adds an Open Alignment initiative sharing red-team traces and safety benchmarks with researchers.\",\n      \"Developers can deploy Grok 4 via xAI's API or self-host the compact Grok Lite variant for on-prem workloads.\",\n      \"New reasoning kernels improve maths, planning, and guarded tool execution across devops workflows.\",\n    ],\n  },\n  {\n    id: \"2025-05-perplexity-sonar-ultra\",\n    title: \"Perplexity debuts Sonar Ultra with autonomous research agents\",\n    slug: \"perplexity-sonar-ultra\",\n    sourceId: \"perplexity\",\n    url: \"https://www.perplexity.ai/blog/sonar-ultra\",\n    summary:\n      \"Sonar Ultra layers multi-agent browsing, fact graphs, and live dashboards over Perplexity's hybrid search stack.\",\n    tags: [\"perplexity\", \"research\", \"agents\"],\n    publishedAt: \"2025-05-28T13:15:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://assets.perplexity.ai/sonar-ultra-card.jpg\",\n    score: 90,\n    content: [\n      \"Perplexity launched Sonar Ultra for analysts who need autonomous research with verifiable citations.\",\n      \"The release adds fact graph visualisations, Slack alerts, and follow-up query automation.\",\n      \"Enterprise plans bundle governance dashboards and redactable research notebooks.\",\n    ],\n  },\n  {\n    id: \"2025-05-microsoft-phi-4\",\n    title: \"Microsoft introduces Phi-4 for Copilot+ PCs and Azure Edge\",\n    slug: \"microsoft-phi-4\",\n    sourceId: \"microsoft\",\n    url: \"https://blogs.microsoft.com/ai/introducing-phi-4\",\n    summary:\n      \"Phi-4 blends efficient transformers with neural radiance caching, powering next-gen on-device copilots and edge inference.\",\n    tags: [\"microsoft\", \"phi-4\", \"edge\"],\n    publishedAt: \"2025-05-09T16:10:00Z\",\n    githubRepo: {\n      fullName: \"microsoft/phi-4-spec\",\n      stars: 12800,\n      deltaStars: 920,\n    },\n    heroImage: \"https://blogs.microsoft.com/wp-content/uploads/2025/05/phi-4-card.jpg\",\n    score: 88,\n    content: [\n      \"Phi-4 ships with quantisation profiles for Copilot+ PCs, Azure Sphere, and HoloLens 3 reference designs.\",\n      \"Microsoft released Responsible AI evaluation packs and open-sourced its safety harness for edge deployments.\",\n      \"A new Phi Playground helps developers fuse sensor data and LLM reasoning for industrial inspection workflows.\",\n    ],\n  },\n  {\n    id: \"2025-04-meta-llama4\",\n    title: \"Meta open-sources Llama 4 120B with streaming adapters\",\n    slug: \"meta-llama-4-120b\",\n    sourceId: \"meta\",\n    url: \"https://ai.meta.com/blog/llama-4/\",\n    summary:\n      \"Llama 4 120B Instruct arrives with fast adapters, mixture routing, and a Responsible Use license for commercial teams.\",\n    tags: [\"meta\", \"open-source\", \"llama4\"],\n    publishedAt: \"2025-04-18T12:00:00Z\",\n    githubRepo: {\n      fullName: \"meta-llama/llama4\",\n      stars: 58000,\n      deltaStars: 4100,\n    },\n    heroImage: \"https://ai.meta.com/static/llama4-card.jpg\",\n    score: 87,\n    content: [\n      \"Meta launched Llama 4 with a new streaming adapter system that lowers latency on commodity GPUs.\",\n      \"Instruction-tuned checkpoints cover multilingual chat, code, and scientific reasoning tasks.\",\n      \"The release includes Llama Guard 4 alignment artifacts and partner audits for transparency.\",\n    ],\n  },\n  {\n    id: \"2025-04-mistral-next\",\n    title: \"Mistral announces Mistral Next 12x24B for retrieval-native apps\",\n    slug: \"mistral-next-12x24b\",\n    sourceId: \"mistral\",\n    url: \"https://mistral.ai/news/mistral-next-12x24b\",\n    summary:\n      \"Mistral Next leverages a MoE architecture optimised for retrieval-augmented generation and multi-agent routing.\",\n    tags: [\"mistral\", \"moe\", \"rag\"],\n    publishedAt: \"2025-04-02T10:00:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://mistral.ai/images/mistral-next-card.jpg\",\n    score: 86,\n    content: [\n      \"Mistral Next 12x24B improves expert sparsity for lower latency while matching dense model accuracy.\",\n      \"The company introduced Retrieval Profiles to tune grounding behaviour across proprietary knowledge bases.\",\n      \"Partners can deploy via managed endpoints, on-prem clusters, or NVIDIA DGX Cloud.\",\n    ],\n  },\n  {\n    id: \"2025-03-huggingface-cascade\",\n    title: \"Hugging Face and AWS release Cascade for open multimodal alignment\",\n    slug: \"huggingface-cascade\",\n    sourceId: \"huggingface\",\n    url: \"https://huggingface.co/blog/cascade\",\n    summary:\n      \"Cascade is a family of open multimodal models trained on curated audio, video, and document corpora with transparent licensing.\",\n    tags: [\"huggingface\", \"multimodal\", \"open\"],\n    publishedAt: \"2025-03-19T11:20:00Z\",\n    githubRepo: {\n      fullName: \"huggingface/cascade\",\n      stars: 9200,\n      deltaStars: 680,\n    },\n    heroImage: \"https://huggingface.co/blog/assets/cascade/cascade-card.jpg\",\n    score: 84,\n    content: [\n      \"Cascade models focus on open evaluation and auditable data pipelines with dataset cards for every modality.\",\n      \"AWS and Hugging Face provide deployment recipes on Bedrock, SageMaker, and serverless inference.\",\n      \"The project ships with evaluation scripts covering DocVQA, VideoQA, and audio captioning benchmarks.\",\n    ],\n  },\n  {\n    id: \"2025-02-stability-sd4\",\n    title: \"Stability AI previews Stable Diffusion 4 with neural render fusion\",\n    slug: \"stability-stable-diffusion-4\",\n    sourceId: \"stability\",\n    url: \"https://stability.ai/news/stable-diffusion-4\",\n    summary:\n      \"Stable Diffusion 4 combines diffusion transformers and neural radiance caching for higher fidelity controllable imagery.\",\n    tags: [\"stability\", \"image\", \"open-source\"],\n    publishedAt: \"2025-02-12T09:30:00Z\",\n    githubRepo: undefined,\n    heroImage: \"https://stability.ai/images/sd4-card.jpg\",\n    score: 82,\n    content: [\n      \"Stable Diffusion 4 adds dual-path rendering for crisp typography, photoreal faces, and cinematic lighting controls.\",\n      \"Stability introduced a creator license allowing commercial use with attribution-based incentives.\",\n      \"Partners can join the Studio Alpha program for direct feedback loops and dataset contributions.\",\n    ],\n  },\n];\n\nexport const weeklyDigest: WeeklyDigest = {\n  weekOf: \"2025-12-22\",\n  headline: \"Weekly Digest | Gemini 3, O2, and Blackwell define the year-end AI surge\",\n  summary:\n    \"Google DeepMind previews Gemini 3, OpenAI ships O2 reasoning, and NVIDIA brings data-center class inference to consumers.\",\n  articleIds: [\n    \"2025-12-nvidia-blackwell-consumer\",\n    \"2025-12-gemini-3-preview\",\n    \"2025-11-openai-o2\",\n    \"2025-10-llama-4-405b\",\n    \"2025-09-openai-gpt5\",\n  ],\n};\n","import type { LearnTrack } from \"@ai-helper/types\";\r\n\r\nexport const learnTracks: LearnTrack[] = [\r\n  {\r\n    id: \"reasoning-native\",\r\n    title: \"Reasoning-Native Engineering\",\r\n    level: \"advanced\",\r\n    timeEstimateHours: 8,\r\n    outcome: \"Architect applications that leverage test-time compute, chain-of-thought verification, and self-correction loops.\",\r\n    modules: [\r\n      {\r\n        title: \"Thinking Chains & Test-Time Compute\",\r\n        objective: \"Master the paradigm shift from zero-shot prompting to verifiable reasoning chains.\",\r\n        resources: [\r\n          {\r\n            title: \"Scaling Test-Time Compute\",\r\n            url: \"https://arxiv.org/abs/2408.03314\",\r\n            type: \"article\",\r\n            description: \"Deep dive into the compute-optimal scaling laws for reasoning models.\"\r\n          },\r\n          {\r\n            title: \"OpenAI O1/O2 System Card\",\r\n            url: \"https://openai.com/index/o1-system-card-safety/\",\r\n            type: \"docs\"\r\n          },\r\n          {\r\n            title: \"Chain of Thought Distillation\",\r\n            url: \"https://github.com/google-research/distilling-step-by-step\",\r\n            type: \"github\"\r\n          }\r\n        ],\r\n        task: \"Implement a 'silent thought' parser that extracts and validates the reasoning steps from an O2 response.\"\r\n      },\r\n      {\r\n        title: \"Monte Carlo Tree Search (MCTS) Agents\",\r\n        objective: \"Build agents that explore multiple future paths before committing to an action.\",\r\n        resources: [\r\n          {\r\n            title: \"AlphaCode 2 Architecture\",\r\n            url: \"https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf\",\r\n            type: \"article\"\r\n          },\r\n          {\r\n            title: \"LangChain Graph reasoning\",\r\n            url: \"https://langchain-ai.github.io/langgraph/\",\r\n            type: \"docs\"\r\n          },\r\n          {\r\n            title: \"Tree of Thoughts Paper\",\r\n            url: \"https://arxiv.org/abs/2305.10601\",\r\n            type: \"article\"\r\n          }\r\n        ],\r\n        task: \"Construct a coding agent that generates 3 candidate solutions and uses unit tests to vote for the best one.\"\r\n      },\r\n      {\r\n        title: \"Verification & Self-Correction\",\r\n        objective: \"Design loops where models critique their own outputs against ground truth or formal logic.\",\r\n        resources: [\r\n          {\r\n            title: \"Constitutional AI\",\r\n            url: \"https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback\",\r\n            type: \"article\"\r\n          },\r\n          {\r\n            title: \"Guardrails for Reasoning\",\r\n            url: \"https://github.com/guardrails-ai/guardrails\",\r\n            type: \"github\"\r\n          },\r\n          {\r\n            title: \"Lean 4 Theorem Proving\",\r\n            url: \"https://leanprover.github.io/\",\r\n            type: \"docs\"\r\n          }\r\n        ],\r\n        task: \"Build a math tutor that formally verifies its step-by-step logic using a Python sandbox.\"\r\n      }\r\n    ],\r\n    capstone: {\r\n      title: \"Autonomous Developer\",\r\n      brief: \"Create a CLI tool that plans, codes, debugs, and verifies a small feature implementation using a reasoning loop.\",\r\n      deliverable: \"GitHub repository with the 'Agentic Loop' logic and demonstration video.\"\r\n    },\r\n    badge: {\r\n      name: \"Cognitive Architect\",\r\n      description: \"Awarded for mastering reasoning-heavy architectures.\",\r\n      icon: \"brain\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"prompt-foundations\",\r\n    \"title\": \"Prompt Engineering Foundations\",\r\n    \"level\": \"beginner\",\r\n    \"timeEstimateHours\": 5,\r\n    \"outcome\": \"Understand LLM fundamentals, craft reliable prompts, and evaluate responses with lightweight checklists.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"LLM Basics & Mental Models\",\r\n        \"objective\": \"Learn how LLMs process instructions, tokens, and safety constraints.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"AI Fundamentals by DeepLearning.AI\",\r\n            \"url\": \"https://www.deeplearning.ai/short-courses/ai-fundamentals/\",\r\n            \"type\": \"video\",\r\n            \"description\": \"Short course covering LLM capabilities, limitations, and terminology.\"\r\n          },\r\n          {\r\n            \"title\": \"OpenAI Prompting Guide\",\r\n            \"url\": \"https://platform.openai.com/docs/guides/prompt-engineering\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"State of Prompting 2025\",\r\n            \"url\": \"https://www.promptingguide.ai/reports/2025\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Explain what temperature, top_p, and system prompts do to a teammate in a short memo.\"\r\n      },\r\n      {\r\n        \"title\": \"Core Prompt Patterns\",\r\n        \"objective\": \"Apply patterns such as role prompting, structured output, and self-checks.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Prompt Engineering Patterns\",\r\n            \"url\": \"https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/patterns\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Promptable Cookbook\",\r\n            \"url\": \"https://github.com/promptable/promptable\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"Structured Outputs with JSON Schema\",\r\n            \"url\": \"https://jsonschema.dev/blog/structured-llm-prompts\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Create three prompts that return JSON objects, each validated against a schema.\"\r\n      },\r\n      {\r\n        \"title\": \"Evaluation & Iteration\",\r\n        \"objective\": \"Measure prompt quality with rubrics, lightweight evals, and user feedback.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Prompt Evaluation with OpenAI Evals\",\r\n            \"url\": \"https://github.com/openai/evals\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"Prompt Matrix Worksheet\",\r\n            \"url\": \"https://promptingguide.ai/tools/prompt-matrix\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"LLM Feedback Loops\",\r\n            \"url\": \"https://blog.langchain.dev/feedback-loops/\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Compare three versions of a support reply prompt and document precision vs. tone trade-offs.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Prompt System Playbook\",\r\n      \"brief\": \"Assemble a short prompt playbook for your team with patterns, guardrails, and evaluation scores.\",\r\n      \"deliverable\": \"Notion or Google Doc with prompt templates plus evaluation results.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Prompt Architect\",\r\n      \"description\": \"Awarded for documenting prompt patterns with evaluation evidence.\",\r\n      \"icon\": \"pen\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"open-source-llms\",\r\n    \"title\": \"Open-Source LLMs with Ollama\",\r\n    \"level\": \"beginner\",\r\n    \"timeEstimateHours\": 6,\r\n    \"outcome\": \"Stand up local LLM inference, quantization, and prompt tooling with Ollama + open models.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Local Setup\",\r\n        \"objective\": \"Install Ollama and run baseline models.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Ollama Quickstart\",\r\n            \"url\": \"https://ollama.com/docs\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Mistral Inference Guide\",\r\n            \"url\": \"https://docs.mistral.ai/getting-started/ollama/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"GPU vs CPU Benchmarks\",\r\n            \"url\": \"https://huggingface.co/blog/llm-performance-gpu\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Run a 7B model locally and record tokens/sec on your hardware.\"\r\n      },\r\n      {\r\n        \"title\": \"Prompt Tooling\",\r\n        \"objective\": \"Layer in prompt libraries and evaluate outputs.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Prompting with Guidance\",\r\n            \"url\": \"https://github.com/guidance-ai/guidance\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"LM Studio Prompt Management\",\r\n            \"url\": \"https://lmstudio.ai/docs/prompts\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Prompt Evaluation Checklist\",\r\n            \"url\": \"https://www.promptingguide.ai/\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Compare two prompt frameworks on the same question set and document differences.\"\r\n      },\r\n      {\r\n        \"title\": \"Optimization & Serving\",\r\n        \"objective\": \"Optimize model loading and expose an API endpoint.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"llama.cpp Quantization\",\r\n            \"url\": \"https://github.com/ggerganov/llama.cpp#quantization\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"Ollama Mod Files\",\r\n            \"url\": \"https://ollama.com/blog/mod-file\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"FastAPI + Ollama\",\r\n            \"url\": \"https://github.com/ollama/ollama/tree/main/examples/fastapi\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Expose a `/generate` endpoint backed by a quantized model of your choice.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Local Model Service\",\r\n      \"brief\": \"Bundle an Ollama mod file + FastAPI server for a specialized prompt workflow.\",\r\n      \"deliverable\": \"Dockerfile and README describing the local deployment steps.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Open Model Engineer\",\r\n      \"description\": \"Awarded for deploying optimized open-source LLMs.\",\r\n      \"icon\": \"chip\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"automation-n8n\",\r\n    \"title\": \"AI Automation with n8n\",\r\n    \"level\": \"intermediate\",\r\n    \"timeEstimateHours\": 7,\r\n    \"outcome\": \"Compose automations that blend LLM calls with business APIs, observability, and human-in-the-loop reviews inside n8n.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Workflow Fundamentals\",\r\n        \"objective\": \"Navigate n8n, understand triggers, and configure environment variables securely.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"n8n Getting Started\",\r\n            \"url\": \"https://docs.n8n.io/hosting/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Best Practices for Secrets\",\r\n            \"url\": \"https://docs.n8n.io/hosting/security/secrets/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Workflow Gallery Inspiration\",\r\n            \"url\": \"https://n8n.io/workflows\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Deploy self-hosted n8n (Docker or cloud) and create a health-check workflow.\"\r\n      },\r\n      {\r\n        \"title\": \"LLM Nodes & Guardrails\",\r\n        \"objective\": \"Wire LLM nodes, retries, and moderation into automated flows.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"n8n OpenAI + Anthropic Nodes\",\r\n            \"url\": \"https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.openAi/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Guardrails with PromptLayer\",\r\n            \"url\": \"https://promptlayer.com/blog/n8n-guardrails\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"Schema Validation in n8n\",\r\n            \"url\": \"https://community.n8n.io/t/how-to-validate-json/31456\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Build a workflow that moderates inbound emails, categorizes them with an LLM, and routes actionable items to Slack.\"\r\n      },\r\n      {\r\n        \"title\": \"Observability & Human Review\",\r\n        \"objective\": \"Implement logging, approval gates, and metrics for ongoing monitoring.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"n8n Workflows for Human-in-the-Loop\",\r\n            \"url\": \"https://docs.n8n.io/workflows/components/human-in-the-loop/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Temporal Workflows + n8n\",\r\n            \"url\": \"https://temporal.io/blog/n8n-temporal-integrations\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"Grafana Dashboards for n8n\",\r\n            \"url\": \"https://github.com/n8n-io/n8n-prometheus-exporter\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Add approval nodes and emit Prometheus metrics for a production-ready automation.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Automation Control Center\",\r\n      \"brief\": \"Ship an n8n automation that triages inbound requests, logs metrics, and includes executive-ready reporting.\",\r\n      \"deliverable\": \"Workflow export + short Loom demonstrating success/failure paths.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Automation Pilot\",\r\n      \"description\": \"Awarded for orchestrating resilient automations with guardrails.\",\r\n      \"icon\": \"switcher\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"rag-weekend\",\r\n    \"title\": \"RAG in a Weekend\",\r\n    \"level\": \"intermediate\",\r\n    \"timeEstimateHours\": 10,\r\n    \"outcome\": \"Ship a retrieval microservice that indexes docs and returns grounded answers with evals.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Retrieval Foundations\",\r\n        \"objective\": \"Understand vector databases, embeddings, and chunking strategies.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Weaviate Vector Databases 101\",\r\n            \"url\": \"https://weaviate.io/blog/vector-database-101\",\r\n            \"type\": \"article\",\r\n            \"description\": \"High-level primer on vector storage and similarity search.\"\r\n          },\r\n          {\r\n            \"title\": \"OpenAI Embeddings Guide\",\r\n            \"url\": \"https://platform.openai.com/docs/guides/embeddings\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Chunking Playground\",\r\n            \"url\": \"https://github.com/openai/openai-cookbook/blob/main/examples/Chunking.ipynb\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Chunk a PDF of your choosing and store embeddings in a local vector database.\"\r\n      },\r\n      {\r\n        \"title\": \"Retriever + LLM Pipeline\",\r\n        \"objective\": \"Implement retrieval chaining and response synthesis.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"LangChain Retrieval QA\",\r\n            \"url\": \"https://python.langchain.com/docs/use_cases/question_answering/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"LlamaIndex RAG Tutorial\",\r\n            \"url\": \"https://docs.llamaindex.ai/en/stable/examples/low_level/recursive_retriever/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Implement RAG with FastAPI\",\r\n            \"url\": \"https://github.com/hwchase17/langchain/blob/master/docs/docs/integrations/fastapi_rag.md\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Expose a `/query` endpoint that fetches supporting passages and responds with citations.\"\r\n      },\r\n      {\r\n        \"title\": \"Evaluation & Hardening\",\r\n        \"objective\": \"Add observability, evaluation, and caching to your RAG system.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"TruLens Evaluation\",\r\n            \"url\": \"https://www.trulens.org/docs/quickstart/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"LangSmith Tracing\",\r\n            \"url\": \"https://docs.smith.langchain.com/user_guide/tracing\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Evaluation Harness\",\r\n            \"url\": \"https://github.com/explodinggradients/ragas\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Log 10 evaluation runs and capture latency + hallucination metrics.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Grounded Support Assistant\",\r\n      \"brief\": \"Build a RAG assistant over your company handbook with source citations and evaluation dashboard.\",\r\n      \"deliverable\": \"GitHub repo + short loom walkthrough of the assistant flow.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"RAG Builder\",\r\n      \"description\": \"Awarded for shipping a production-ready retrieval assistant.\",\r\n      \"icon\": \"sparkles\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"agents-101\",\r\n    \"title\": \"Agents 101 (Tools & Functions)\",\r\n    \"level\": \"intermediate\",\r\n    \"timeEstimateHours\": 8,\r\n    \"outcome\": \"Design agents that orchestrate tools safely using function calling and guardrails.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Agent Patterns\",\r\n        \"objective\": \"Survey single vs. multi-agent architectures and planning loops.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Anthropic Cookbook: Agents\",\r\n            \"url\": \"https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"OpenAI Function Calling\",\r\n            \"url\": \"https://platform.openai.com/docs/guides/function-calling\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"SmolAgents Walkthrough\",\r\n            \"url\": \"https://github.com/huggingface/smolagents\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Diagram an agent loop for a research assistant that calls web + code tools.\"\r\n      },\r\n      {\r\n        \"title\": \"Tooling & Orchestration\",\r\n        \"objective\": \"Implement tool registration and result parsing.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"LangChain Agent Toolkits\",\r\n            \"url\": \"https://python.langchain.com/docs/modules/agents/toolkits/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"ReAct Pattern in Practice\",\r\n            \"url\": \"https://arxiv.org/abs/2210.03629\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"Agent Evaluation Harness\",\r\n            \"url\": \"https://github.com/langchain-ai/langchain/tree/master/templates/agent-evals\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Implement a sandboxed agent that calls two tools and handles tool errors gracefully.\"\r\n      },\r\n      {\r\n        \"title\": \"Evaluation & Safety\",\r\n        \"objective\": \"Add guardrails, timeouts, and monitoring for agent operations.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Prompt Layer Logging\",\r\n            \"url\": \"https://promptlayer.com/docs\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"MLflow Prompt Evaluation\",\r\n            \"url\": \"https://mlflow.org/docs/latest/llms/\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Structural Guardrails\",\r\n            \"url\": \"https://github.com/guardrails-ai/guardrails\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Ship evaluation harness for 20 scripted agent conversations with guardrail checks.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Analyst Assistant\",\r\n      \"brief\": \"Build an agent that ingests CSV data, runs tool-based insights, and returns an executive summary.\",\r\n      \"deliverable\": \"Notebook or service with evaluation logs + summary sample.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Agent Orchestrator\",\r\n      \"description\": \"Awarded for shipping a resilient tool-using agent.\",\r\n      \"icon\": \"workflow\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"agent-ops\",\r\n    \"title\": \"AgentOps & LLM Observability\",\r\n    \"level\": \"advanced\",\r\n    \"timeEstimateHours\": 9,\r\n    \"outcome\": \"Monitor, evaluate, and roll out agent-driven products with SLOs, alerting, and incident workflows.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Telemetry & Tracing\",\r\n        \"objective\": \"Capture spans, prompts, and tool invocations for debugging.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"LangSmith Production Playbook\",\r\n            \"url\": \"https://docs.smith.langchain.com/user_guide/production\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"OpenTelemetry for LLM Apps\",\r\n            \"url\": \"https://github.com/opentelemetry-ml/opentelemetry-llm\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"PromptOps Runbooks\",\r\n            \"url\": \"https://promptops.ai/runbooks\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Instrument an agent workflow with traces that capture prompt, tool latency, and errors.\"\r\n      },\r\n      {\r\n        \"title\": \"Evaluation Pipelines\",\r\n        \"objective\": \"Automate regression suites and safety checks for releases.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"DeepEval Cookbook\",\r\n            \"url\": \"https://github.com/confident-ai/deepeval\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"Testing Structured Outputs\",\r\n            \"url\": \"https://docs.arize.com/phoenix/docs/llm-evaluations\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Risk Scenario Playbooks\",\r\n            \"url\": \"https://github.com/langchain-ai/agent-risk-scenarios\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Automate nightly evals with pass/fail thresholds and alerting to Slack/Teams.\"\r\n      },\r\n      {\r\n        \"title\": \"Rollouts & Incident Response\",\r\n        \"objective\": \"Plan gradual rollouts, fallbacks, and live incident recovery.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Canary Releases for LLMs\",\r\n            \"url\": \"https://blog.honeycomb.io/canary-llm\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"Incident Templates for Agent Teams\",\r\n            \"url\": \"https://github.com/ai-incident-response/templates\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"PagerDuty x LLM Alerts\",\r\n            \"url\": \"https://support.pagerduty.com/docs/aiops\",\r\n            \"type\": \"docs\"\r\n          }\r\n        ],\r\n        \"task\": \"Design and document a rollout plan with rollback paths and incident command checklist.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Agent Reliability Dashboard\",\r\n      \"brief\": \"Deliver a monitoring pack with dashboards, alerts, and weekly health reports for an agent product.\",\r\n      \"deliverable\": \"Grafana/Looker screenshots + incident documentation pack.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Reliability Lead\",\r\n      \"description\": \"Awarded for operationalizing agent monitoring with incident playbooks.\",\r\n      \"icon\": \"pulse\"\r\n    }\r\n  },\r\n  {\r\n    \"id\": \"multimodal-labs\",\r\n    \"title\": \"Multimodal Creation Studio\",\r\n    \"level\": \"advanced\",\r\n    \"timeEstimateHours\": 8,\r\n    \"outcome\": \"Prototype end-to-end multimodal experiences spanning image, audio, and video synthesis with alignment controls.\",\r\n    \"modules\": [\r\n      {\r\n        \"title\": \"Image & Video Foundations\",\r\n        \"objective\": \"Work with diffusion, temporal attention, and control nets.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Stable Video Diffusion\",\r\n            \"url\": \"https://github.com/Stability-AI/stable-video-diffusion\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"ComfyUI Advanced Nodes\",\r\n            \"url\": \"https://comfyui.org/docs/advanced-nodes\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Temporal Attention Explained\",\r\n            \"url\": \"https://arxiv.org/abs/2401.01234\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Generate a storyboard with reference frames and export to MP4.\"\r\n      },\r\n      {\r\n        \"title\": \"Audio & Voice Layers\",\r\n        \"objective\": \"Blend speech synthesis, Foley, and soundtrack generation.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Meta AudioCraft\",\r\n            \"url\": \"https://github.com/facebookresearch/audiocraft\",\r\n            \"type\": \"github\"\r\n          },\r\n          {\r\n            \"title\": \"ElevenLabs Voice Lab\",\r\n            \"url\": \"https://elevenlabs.io/docs/voice-lab\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Suno Studio Workflow\",\r\n            \"url\": \"https://help.suno.ai/hc/en-us/articles/13986121412115-Workflow\",\r\n            \"type\": \"article\"\r\n          }\r\n        ],\r\n        \"task\": \"Design a 30-second trailer with scripted narration and matched soundtrack.\"\r\n      },\r\n      {\r\n        \"title\": \"Safety & Distribution\",\r\n        \"objective\": \"Apply watermarking, metadata, and usage governance.\",\r\n        \"resources\": [\r\n          {\r\n            \"title\": \"Content Authenticity Initiative\",\r\n            \"url\": \"https://contentauthenticity.org/standards\",\r\n            \"type\": \"article\"\r\n          },\r\n          {\r\n            \"title\": \"Adobe Firefly Usage Guidelines\",\r\n            \"url\": \"https://helpx.adobe.com/firefly/using/guidelines.html\",\r\n            \"type\": \"docs\"\r\n          },\r\n          {\r\n            \"title\": \"Metadata Watermarking\",\r\n            \"url\": \"https://github.com/contentauth/c2pa\",\r\n            \"type\": \"github\"\r\n          }\r\n        ],\r\n        \"task\": \"Export assets with provenance metadata and watermark verification report.\"\r\n      }\r\n    ],\r\n    \"capstone\": {\r\n      \"title\": \"Multimodal Launch Kit\",\r\n      \"brief\": \"Produce a 60-second campaign video with companion assets and a compliance checklist.\",\r\n      \"deliverable\": \"Asset bundle + checklist covering rights, metadata, and export settings.\"\r\n    },\r\n    \"badge\": {\r\n      \"name\": \"Creative Director\",\r\n      \"description\": \"Awarded for shipping an aligned multimodal experience.\",\r\n      \"icon\": \"palette\"\r\n    }\r\n  }\r\n];\r\n\r\n"],"names":[],"mappings":"wGAEO,IAAM,EAAqC,CAChD,gBAAiB,CAAC,QAAS,oBAAqB,iBAAkB,SAAS,CAC3E,WAAY,CACV,CACE,GAAI,OACJ,KAAM,OACN,YAAa,8DACb,gBAAgB,EAChB,KAAM,GACR,EACA,CACE,GAAI,QACJ,KAAM,QACN,YAAa,mEACb,gBAAgB,EAChB,KAAM,GACR,EACA,CACE,GAAI,YACJ,KAAM,YACN,YAAa,sDACb,gBAAgB,EAChB,KAAM,GACR,EACA,CACE,GAAI,YACJ,KAAM,YACN,YAAa,oEACb,gBAAgB,EAChB,KAAM,GACR,EACA,CACE,GAAI,UACJ,KAAM,WACN,YAAa,sEACb,gBAAgB,EAChB,KAAM,OACR,EACD,AACH,EAEa,EAAgC,CAC3C,CACE,GAAI,QACJ,KAAM,QACN,SAAU,SACV,YAAa,aACb,cAAe,IACf,QAAS,cACT,aAAc,MACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,2CAA4C,EAChH,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,2CAA4C,EACjH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAClH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,6BAA8B,EACvG,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,IAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,KAAM,SAAU,KAAM,EACzD,CAAE,KAAM,WAAY,gBAAiB,IAAK,SAAU,KAAM,EAC3D,CACD,QAAS,CACP,UAAW,IACX,WAAY,CAAC,OAAQ,QAAS,QAAS,QAAS,QAAQ,CACxD,MAAO,kGACT,EACA,QAAS,4CACT,QAAS,iGACT,QAAS,CACP,4CACA,gDACD,AACH,EACA,CACE,GAAI,oBACJ,KAAM,oBACN,SAAU,YACV,YAAa,aACb,cAAe,KACf,QAAS,cACT,aAAc,MACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kCAAmC,EACvG,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kCAAmC,EACxG,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,IAAM,OAAQ,kCAAmC,EAC3G,CAAE,YAAa,YAAa,MAAO,GAAM,gBAAiB,KAAO,OAAQ,kCAAmC,EAC5G,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,EAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,GAAM,SAAU,KAAM,EAC1D,CACD,QAAS,CACP,UAAW,KACX,WAAY,CAAC,OAAQ,QAAQ,CAC7B,MAAO,8GACT,EACA,QAAS,mDACT,QAAS,6GACT,QAAS,CACP,mDACA,mCACD,AACH,EACA,CACE,GAAI,iBACJ,KAAM,iBACN,SAAU,kBACV,YAAa,aACb,cAAe,IACf,QAAS,cACT,aAAc,MACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,sDAAuD,EAC3H,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,sDAAuD,EAC5H,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kDAAmD,EAC5H,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kDAAmD,EAC5H,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,IAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,KAAM,SAAU,KAAM,EAC1D,CACD,QAAS,CACP,UAAW,IACX,WAAY,CAAC,OAAQ,QAAS,QAAS,QAAQ,CAC/C,MAAO,+FACT,EACA,QAAS,uDACT,QAAS,0GACT,QAAS,CACP,uDACA,+CACD,AACH,EACA,CACE,GAAI,SACJ,KAAM,SACN,SAAU,MACV,YAAa,aACb,cAAe,MACf,QAAS,cACT,aAAc,MACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,0BAA2B,EAC/F,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,0BAA2B,EAChG,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,0BAA2B,EACpG,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,0BAA2B,EACpG,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,IAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,KAAM,SAAU,KAAM,EAC1D,CACD,QAAS,CACP,UAAW,MACX,WAAY,CAAC,OAAQ,QAAQ,CAC7B,MAAO,kFACT,EACA,QAAS,2BACT,QAAS,kGACT,QAAS,CACP,2BACA,yBACD,AACH,EACA,CACE,GAAI,yBACJ,KAAM,yBACN,SAAU,aACV,YAAa,aACb,cAAe,KACf,QAAS,cACT,aAAc,MACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,IAAM,OAAQ,4CAA6C,EAChH,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,IAAM,OAAQ,4CAA6C,EACjH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,IAAM,OAAQ,4CAA6C,EACrH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,IAAM,OAAQ,4CAA6C,EACrH,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,4CAA6C,EACnH,CACD,QAAS,CACP,CAAE,KAAM,WAAY,gBAAiB,GAAK,SAAU,KAAM,EAC3D,CACD,QAAS,CACP,UAAW,KACX,WAAY,CAAC,OAAQ,MAAM,CAC3B,MAAO,8FACT,EACA,QAAS,6CACT,QAAS,sGACT,QAAS,CACP,6CACA,6BACD,AACH,EACA,CACE,GAAI,eACJ,KAAM,wBACN,SAAU,OACV,YAAa,aACb,cAAe,MACf,QAAS,cACT,aAAc,YACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,mCAAoC,EACxG,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,mCAAoC,EACzG,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,mCAAoC,EAC7G,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,mCAAoC,EAC7G,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,EAAE,CACX,QAAS,CACP,UAAW,MACX,WAAY,CAAC,OAAQ,OAAO,CAC5B,MAAO,2FACT,EACA,QAAS,oCACT,QAAS,+FACT,QAAS,CACP,oCACA,gCACD,AACH,EACA,CACE,GAAI,sBACJ,KAAM,sBACN,SAAU,aACV,YAAa,aACb,cAAe,MACf,QAAS,SACT,aAAc,SACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,6CAA8C,EAClH,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,6CAA8C,EACnH,CAAE,YAAa,YAAa,MAAO,GAAM,gBAAiB,KAAO,OAAQ,6CAA8C,EACvH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,6CAA8C,EACvH,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,8CAA+C,EACrH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,IAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,KAAM,SAAU,KAAM,EAC1D,CACD,QAAS,CACP,UAAW,MACX,WAAY,CAAC,OAAO,CACpB,MAAO,gGACT,EACA,QAAS,8CACT,QAAS,2GACT,QAAS,CACP,8CACA,0BACD,AACH,EACA,CACE,GAAI,QACJ,KAAM,QACN,SAAU,YACV,YAAa,aACb,cAAe,MACf,QAAS,iBACT,aAAc,SACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,GAAK,OAAQ,kDAAmD,EACrH,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kDAAmD,EACxH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,IAAM,OAAQ,kDAAmD,EAC3H,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,kDAAmD,EAC5H,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,kDAAmD,EACzH,CACD,QAAS,CACP,CAAE,KAAM,QAAS,gBAAiB,IAAK,SAAU,KAAM,EACvD,CAAE,KAAM,SAAU,gBAAiB,IAAK,SAAU,KAAM,EACzD,CACD,QAAS,CACP,UAAW,MACX,WAAY,CAAC,OAAQ,SAAS,CAC9B,MAAO,4GACT,EACA,QAAS,mDACT,QAAS,0HACT,QAAS,CACP,mDACA,+CACD,AACH,EACA,CACE,GAAI,SACJ,KAAM,kBACN,SAAU,aACV,YAAa,aACb,cAAe,KACf,QAAS,aACT,aAAc,YACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAC7G,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAC9G,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAClH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAClH,CAAE,YAAa,UAAW,MAAO,IAAK,gBAAiB,IAAM,OAAQ,wCAAyC,EAC/G,CACD,QAAS,CACP,CAAE,KAAM,WAAY,gBAAiB,IAAM,SAAU,KAAM,EAC5D,CACD,QAAS,CACP,UAAW,KACX,WAAY,CAAC,OAAO,CACpB,MAAO,+EACT,EACA,QAAS,yCACT,QAAS,iHACT,QAAS,CACP,yCACA,oDACD,AACH,EACA,CACE,GAAI,gBACJ,KAAM,gBACN,SAAU,aACV,YAAa,aACb,cAAe,MACf,QAAS,cACT,aAAc,YACd,WAAY,CACV,CAAE,YAAa,OAAQ,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAC7G,CAAE,YAAa,QAAS,MAAO,KAAM,gBAAiB,IAAM,OAAQ,wCAAyC,EAC7G,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,IAAM,OAAQ,wCAAyC,EACjH,CAAE,YAAa,YAAa,MAAO,KAAM,gBAAiB,KAAO,OAAQ,wCAAyC,EAClH,CAAE,YAAa,UAAW,MAAO,EAAK,gBAAiB,GAAK,OAAQ,wEAAyE,EAC9I,CACD,QAAS,EAAE,CACX,QAAS,CACP,UAAW,MACX,WAAY,CAAC,OAAO,CACpB,MAAO,sFACT,EACA,QAAS,yCACT,QAAS,sGACT,QAAS,CACP,yCACA,+DACD,AACH,EACD,oCCzVM,IAAM,EAAwC,CACnD,CACE,GAAI,eACJ,KAAM,0BACN,SAAU,OACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,SAAU,CACZ,EACA,UAAW,cACX,WAAY,YACZ,QAAS,wCACT,KAAM,CAAC,cAAe,aAAc,WAAW,CAC/C,WAAY,CACV,wCACA,gCACD,AACH,EACA,CACE,GAAI,YACJ,KAAM,YACN,SAAU,SACV,YAAa,aACb,cAAe,IACf,QAAS,CACP,SAAU,MACV,MAAO,GACP,OAAQ,EACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,wBACT,KAAM,CAAC,YAAa,OAAQ,SAAS,CACrC,WAAY,CACV,wBACA,6CACD,AACH,EACA,CACE,GAAI,yBACJ,KAAM,2BACN,SAAU,kBACV,YAAa,aACb,cAAe,IACf,QAAS,CACP,SAAU,MACV,MAAO,GACP,OAAQ,EACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,mCACT,KAAM,CAAC,mBAAoB,aAAc,UAAU,CACnD,WAAY,CACV,mCACA,mCACD,AACH,EACA,CACE,GAAI,QACJ,KAAM,QACN,SAAU,SACV,YAAa,aACb,cAAe,IACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,KACR,SAAU,GACZ,EACA,UAAW,cACX,WAAY,MACZ,QAAS,4CACT,KAAM,CAAC,aAAc,WAAY,SAAS,CAC1C,WAAY,CACV,4CACA,gDACD,AACH,EACA,CACE,GAAI,gBACJ,KAAM,gBACN,SAAU,SACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,GACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,wDACT,KAAM,CAAC,iBAAkB,aAAc,WAAW,CAClD,WAAY,CACV,wDACD,AACH,EACA,CACE,GAAI,oBACJ,KAAM,oBACN,SAAU,YACV,YAAa,aACb,cAAe,KACf,QAAS,CACP,SAAU,MACV,MAAO,EACP,OAAQ,EACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,mDACT,KAAM,CAAC,aAAc,aAAc,eAAe,CAClD,WAAY,CACV,mDACA,mCACD,AACH,EACA,CACE,GAAI,iBACJ,KAAM,iBACN,SAAU,kBACV,YAAa,aACb,cAAe,IACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,IACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,uDACT,KAAM,CAAC,aAAc,YAAa,QAAQ,CAC1C,WAAY,CACV,uDACA,+CACD,AACH,EACA,CACE,GAAI,SACJ,KAAM,SACN,SAAU,MACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,IACV,EACA,UAAW,cACX,WAAY,MACZ,QAAS,2BACT,KAAM,CAAC,MAAO,eAAgB,eAAe,CAC7C,WAAY,CACV,2BACA,yBACD,AACH,EACA,CACE,GAAI,yBACJ,KAAM,yBACN,SAAU,aACV,YAAa,aACb,cAAe,KACf,QAAS,CACP,SAAU,MACV,SAAU,EACZ,EACA,UAAW,cACX,WAAY,MACZ,QAAS,6CACT,KAAM,CAAC,WAAY,SAAU,YAAY,CACzC,WAAY,CACV,6CACA,6BACD,AACH,EACA,CACE,GAAI,eACJ,KAAM,wBACN,SAAU,OACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,SAAU,CACZ,EACA,UAAW,cACX,WAAY,YACZ,QAAS,oCACT,KAAM,CAAC,cAAe,WAAY,OAAO,CACzC,WAAY,CACV,oCACA,gCACD,AACH,EACA,CACE,GAAI,sBACJ,KAAM,sBACN,SAAU,aACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,IACV,EACA,UAAW,QACX,WAAY,SACZ,QAAS,8CACT,KAAM,CAAC,MAAO,MAAO,SAAS,CAC9B,WAAY,CACV,8CACA,0BACD,AACH,EACA,CACE,GAAI,QACJ,KAAM,QACN,SAAU,YACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,MAAO,IACP,OAAQ,GACV,EACA,UAAW,QACX,WAAY,SACZ,QAAS,mDACT,KAAM,CAAC,OAAQ,UAAW,YAAY,CACtC,WAAY,CACV,mDACA,+CACD,AACH,EACA,CACE,GAAI,SACJ,KAAM,kBACN,SAAU,aACV,YAAa,aACb,cAAe,KACf,QAAS,CACP,SAAU,MACV,SAAU,GACZ,EACA,UAAW,QACX,WAAY,SACZ,QAAS,yCACT,KAAM,CAAC,MAAO,YAAa,YAAY,CACvC,WAAY,CACV,yCACA,oDACD,AACH,EACA,CACE,GAAI,gBACJ,KAAM,gBACN,SAAU,aACV,YAAa,aACb,cAAe,MACf,QAAS,CACP,SAAU,MACV,SAAU,CACZ,EACA,UAAW,cACX,WAAY,YACZ,QAAS,yCACT,KAAM,CAAC,MAAO,cAAe,WAAW,CACxC,WAAY,CACV,yCACA,+DACD,AACH,EACD,iGCpRM,IAAM,EAA4B,CACvC,CACE,GAAI,SACJ,KAAM,SACN,IAAK,0BACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,CACV,EACA,CACE,GAAI,YACJ,KAAM,YACN,IAAK,iCACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,WACJ,KAAM,kBACN,IAAK,kDACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,MACJ,KAAM,MACN,IAAK,oBACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,EACV,EACA,CACE,GAAI,aACJ,KAAM,aACN,IAAK,iCACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,OACJ,KAAM,UACN,IAAK,2BACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,UACJ,KAAM,aACN,IAAK,0BACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,cACJ,KAAM,eACN,IAAK,8BACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,EACV,EACA,CACE,GAAI,YACJ,KAAM,eACN,IAAK,kCACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACA,CACE,GAAI,YACJ,KAAM,eACN,IAAK,4BACL,SAAU,CAAC,UAAW,UAAU,CAChC,OAAQ,GACV,EACD,CAEY,EAAiC,CAC5C,CACE,GAAI,oCACJ,MAAO,sEACP,KAAM,4BACN,SAAU,cACV,IAAK,sDACL,QACE,6GACF,KAAM,CAAC,WAAY,OAAQ,YAAY,CACvC,YAAa,uBACb,gBAAY,EACZ,UAAW,sDACX,MAAO,GACP,QAAS,CACP,oHACA,wFACA,kFACD,AACH,EACA,CACE,GAAI,2BACJ,MAAO,gEACP,KAAM,yBACN,SAAU,WACV,IAAK,kEACL,QACE,iHACF,KAAM,CAAC,SAAU,WAAY,mBAAmB,CAChD,YAAa,uBACb,gBAAY,EACZ,UAAW,sDACX,MAAO,GACP,QAAS,CACP,0HACA,+GACA,uFACD,AACH,EACA,CACE,GAAI,oBACJ,MAAO,wDACP,KAAM,sBACN,SAAU,SACV,IAAK,6CACL,QACE,+IACF,KAAM,CAAC,YAAa,OAAQ,SAAS,CACrC,YAAa,uBACb,gBAAY,EACZ,UAAW,wCACX,MAAO,GACP,QAAS,CACP,kHACA,gHACA,uGACD,AACH,EACA,CACE,GAAI,uBACJ,MAAO,kDACP,KAAM,oBACN,SAAU,OACV,IAAK,wCACL,QACE,qHACF,KAAM,CAAC,cAAe,aAAc,WAAW,CAC/C,YAAa,uBACb,WAAY,CACV,SAAU,oBACV,MAAO,KACP,WAAY,IACd,EACA,UAAW,mDACX,MAAO,GACP,QAAS,CACP,qGACA,oGACA,2FACD,AACH,EACA,CACE,GAAI,sBACJ,MAAO,2DACP,KAAM,sBACN,SAAU,SACV,IAAK,4CACL,QACE,iIACF,KAAM,CAAC,QAAS,aAAc,SAAS,CACvC,YAAa,uBACb,gBAAY,EACZ,UAAW,mDACX,MAAO,GACP,QAAS,CACP,oHACA,wIACA,sGACD,AACH,EACA,CACE,GAAI,sCACJ,MAAO,gEACP,KAAM,8BACN,SAAU,YACV,IAAK,mDACL,QACE,iHACF,KAAM,CAAC,SAAU,aAAc,aAAa,CAC5C,YAAa,uBACb,gBAAY,EACZ,UAAW,uDACX,MAAO,GACP,QAAS,CACP,sHACA,sGACA,+FACD,AACH,EACA,CACE,GAAI,yBACJ,MAAO,iEACP,KAAM,wBACN,SAAU,WACV,IAAK,uDACL,QACE,uHACF,KAAM,CAAC,SAAU,aAAc,YAAY,CAC3C,YAAa,uBACb,gBAAY,EACZ,UAAW,qDACX,MAAO,GACP,QAAS,CACP,kHACA,4GACA,oFACD,AACH,EACA,CACE,GAAI,qBACJ,MAAO,+CACP,KAAM,qBACN,SAAU,MACV,IAAK,2BACL,QACE,kIACF,KAAM,CAAC,OAAQ,MAAO,YAAY,CAClC,YAAa,uBACb,gBAAY,EACZ,UAAW,sCACX,MAAO,GACP,QAAS,CACP,2GACA,+GACA,qGACD,AACH,EACA,CACE,GAAI,iCACJ,MAAO,gEACP,KAAM,yBACN,SAAU,aACV,IAAK,6CACL,QACE,mHACF,KAAM,CAAC,aAAc,WAAY,SAAS,CAC1C,YAAa,uBACb,gBAAY,EACZ,UAAW,oDACX,MAAO,GACP,QAAS,CACP,uGACA,4FACA,mFACD,AACH,EACA,CACE,GAAI,0BACJ,MAAO,6DACP,KAAM,kBACN,SAAU,YACV,IAAK,mDACL,QACE,6HACF,KAAM,CAAC,YAAa,QAAS,OAAO,CACpC,YAAa,uBACb,WAAY,CACV,SAAU,uBACV,MAAO,MACP,WAAY,GACd,EACA,UAAW,wEACX,MAAO,GACP,QAAS,CACP,2GACA,+GACA,gHACD,AACH,EACA,CACE,GAAI,sBACJ,MAAO,yDACP,KAAM,oBACN,SAAU,OACV,IAAK,oCACL,QACE,yHACF,KAAM,CAAC,OAAQ,cAAe,SAAS,CACvC,YAAa,uBACb,WAAY,CACV,SAAU,oBACV,MAAO,KACP,WAAY,IACd,EACA,UAAW,6CACX,MAAO,GACP,QAAS,CACP,mGACA,+FACA,8FACD,AACH,EACA,CACE,GAAI,uBACJ,MAAO,kEACP,KAAM,sBACN,SAAU,UACV,IAAK,8CACL,QACE,kHACF,KAAM,CAAC,UAAW,MAAO,MAAM,CAC/B,YAAa,uBACb,gBAAY,EACZ,UAAW,kDACX,MAAO,GACP,QAAS,CACP,sGACA,4GACA,oFACD,AACH,EACA,CACE,GAAI,8BACJ,MAAO,qEACP,KAAM,sBACN,SAAU,cACV,IAAK,sCACL,QACE,kIACF,KAAM,CAAC,cAAe,aAAc,OAAO,CAC3C,YAAa,uBACb,WAAY,CACV,SAAU,sBACV,MAAO,KACP,WAAY,GACd,EACA,UAAW,8DACX,MAAO,GACP,QAAS,CACP,8GACA,mGACA,uGACD,AACH,EACA,CACE,GAAI,wBACJ,MAAO,qEACP,KAAM,+BACN,SAAU,YACV,IAAK,+CACL,QACE,2HACF,KAAM,CAAC,YAAa,QAAS,cAAc,CAC3C,YAAa,uBACb,gBAAY,EACZ,UAAW,2CACX,MAAO,GACP,QAAS,CACP,sHACA,oGACA,kGACD,AACH,EACD,CAEY,EAA6B,CACxC,OAAQ,aACR,SAAU,2EACV,QACE,4HACF,WAAY,CACV,oCACA,2BACA,oBACA,uBACA,sBACD,AACH,qDClXO,IAAM,EAA4B,CACvC,CACE,GAAI,mBACJ,MAAO,+BACP,MAAO,WACP,kBAAmB,EACnB,QAAS,oHACT,QAAS,CACP,CACE,MAAO,sCACP,UAAW,qFACX,UAAW,CACT,CACE,MAAO,4BACP,IAAK,mCACL,KAAM,UACN,YAAa,uEACf,EACA,CACE,MAAO,2BACP,IAAK,kDACL,KAAM,MACR,EACA,CACE,MAAO,gCACP,IAAK,6DACL,KAAM,QACR,EACD,CACD,KAAM,0GACR,EACA,CACE,MAAO,wCACP,UAAW,kFACX,UAAW,CACT,CACE,MAAO,2BACP,IAAK,sFACL,KAAM,SACR,EACA,CACE,MAAO,4BACP,IAAK,4CACL,KAAM,MACR,EACA,CACE,MAAO,yBACP,IAAK,mCACL,KAAM,SACR,EACD,CACD,KAAM,6GACR,EACA,CACE,MAAO,iCACP,UAAW,6FACX,UAAW,CACT,CACE,MAAO,oBACP,IAAK,kFACL,KAAM,SACR,EACA,CACE,MAAO,2BACP,IAAK,8CACL,KAAM,QACR,EACA,CACE,MAAO,yBACP,IAAK,gCACL,KAAM,MACR,EACD,CACD,KAAM,0FACR,EACD,CACD,SAAU,CACR,MAAO,uBACP,MAAO,mHACP,YAAa,0EACf,EACA,MAAO,CACL,KAAM,sBACN,YAAa,uDACb,KAAM,OACR,CACF,EACA,CACE,GAAM,qBACN,MAAS,iCACT,MAAS,WACT,kBAAqB,EACrB,QAAW,2GACX,QAAW,CACT,CACE,MAAS,6BACT,UAAa,uEACb,UAAa,CACX,CACE,MAAS,qCACT,IAAO,6DACP,KAAQ,QACR,YAAe,uEACjB,EACA,CACE,MAAS,yBACT,IAAO,6DACP,KAAQ,MACV,EACA,CACE,MAAS,0BACT,IAAO,6CACP,KAAQ,SACV,EACD,CACD,KAAQ,uFACV,EACA,CACE,MAAS,uBACT,UAAa,6EACb,UAAa,CACX,CACE,MAAS,8BACT,IAAO,mFACP,KAAQ,MACV,EACA,CACE,MAAS,sBACT,IAAO,2CACP,KAAQ,QACV,EACA,CACE,MAAS,sCACT,IAAO,qDACP,KAAQ,SACV,EACD,CACD,KAAQ,iFACV,EACA,CACE,MAAS,yBACT,UAAa,6EACb,UAAa,CACX,CACE,MAAS,sCACT,IAAO,kCACP,KAAQ,QACV,EACA,CACE,MAAS,0BACT,IAAO,gDACP,KAAQ,MACV,EACA,CACE,MAAS,qBACT,IAAO,6CACP,KAAQ,SACV,EACD,CACD,KAAQ,8FACV,EACD,CACD,SAAY,CACV,MAAS,yBACT,MAAS,mGACT,YAAe,qEACjB,EACA,MAAS,CACP,KAAQ,mBACR,YAAe,oEACf,KAAQ,KACV,CACF,EACA,CACE,GAAM,mBACN,MAAS,+BACT,MAAS,WACT,kBAAqB,EACrB,QAAW,4FACX,QAAW,CACT,CACE,MAAS,cACT,UAAa,0CACb,UAAa,CACX,CACE,MAAS,oBACT,IAAO,0BACP,KAAQ,MACV,EACA,CACE,MAAS,0BACT,IAAO,kDACP,KAAQ,MACV,EACA,CACE,MAAS,wBACT,IAAO,kDACP,KAAQ,SACV,EACD,CACD,KAAQ,gEACV,EACA,CACE,MAAS,iBACT,UAAa,kDACb,UAAa,CACX,CACE,MAAS,0BACT,IAAO,0CACP,KAAQ,QACV,EACA,CACE,MAAS,8BACT,IAAO,mCACP,KAAQ,MACV,EACA,CACE,MAAS,8BACT,IAAO,iCACP,KAAQ,SACV,EACD,CACD,KAAQ,kFACV,EACA,CACE,MAAS,yBACT,UAAa,qDACb,UAAa,CACX,CACE,MAAS,yBACT,IAAO,sDACP,KAAQ,QACV,EACA,CACE,MAAS,mBACT,IAAO,mCACP,KAAQ,SACV,EACA,CACE,MAAS,mBACT,IAAO,8DACP,KAAQ,QACV,EACD,CACD,KAAQ,2EACV,EACD,CACD,SAAY,CACV,MAAS,sBACT,MAAS,gFACT,YAAe,8DACjB,EACA,MAAS,CACP,KAAQ,sBACR,YAAe,oDACf,KAAQ,MACV,CACF,EACA,CACE,GAAM,iBACN,MAAS,yBACT,MAAS,eACT,kBAAqB,EACrB,QAAW,wHACX,QAAW,CACT,CACE,MAAS,wBACT,UAAa,mFACb,UAAa,CACX,CACE,MAAS,sBACT,IAAO,+BACP,KAAQ,MACV,EACA,CACE,MAAS,6BACT,IAAO,gDACP,KAAQ,MACV,EACA,CACE,MAAS,+BACT,IAAO,2BACP,KAAQ,SACV,EACD,CACD,KAAQ,8EACV,EACA,CACE,MAAS,yBACT,UAAa,gEACb,UAAa,CACX,CACE,MAAS,+BACT,IAAO,4EACP,KAAQ,MACV,EACA,CACE,MAAS,8BACT,IAAO,8CACP,KAAQ,SACV,EACA,CACE,MAAS,2BACT,IAAO,wDACP,KAAQ,SACV,EACD,CACD,KAAQ,qHACV,EACA,CACE,MAAS,+BACT,UAAa,yEACb,UAAa,CACX,CACE,MAAS,sCACT,IAAO,8DACP,KAAQ,MACV,EACA,CACE,MAAS,2BACT,IAAO,qDACP,KAAQ,SACV,EACA,CACE,MAAS,6BACT,IAAO,oDACP,KAAQ,QACV,EACD,CACD,KAAQ,mFACV,EACD,CACD,SAAY,CACV,MAAS,4BACT,MAAS,8GACT,YAAe,mEACjB,EACA,MAAS,CACP,KAAQ,mBACR,YAAe,mEACf,KAAQ,UACV,CACF,EACA,CACE,GAAM,cACN,MAAS,mBACT,MAAS,eACT,kBAAqB,GACrB,QAAW,2FACX,QAAW,CACT,CACE,MAAS,wBACT,UAAa,oEACb,UAAa,CACX,CACE,MAAS,gCACT,IAAO,+CACP,KAAQ,UACR,YAAe,4DACjB,EACA,CACE,MAAS,0BACT,IAAO,qDACP,KAAQ,MACV,EACA,CACE,MAAS,sBACT,IAAO,8EACP,KAAQ,QACV,EACD,CACD,KAAQ,+EACV,EACA,CACE,MAAS,2BACT,UAAa,uDACb,UAAa,CACX,CACE,MAAS,yBACT,IAAO,kEACP,KAAQ,MACV,EACA,CACE,MAAS,0BACT,IAAO,+EACP,KAAQ,MACV,EACA,CACE,MAAS,6BACT,IAAO,2FACP,KAAQ,QACV,EACD,CACD,KAAQ,0FACV,EACA,CACE,MAAS,yBACT,UAAa,iEACb,UAAa,CACX,CACE,MAAS,qBACT,IAAO,2CACP,KAAQ,MACV,EACA,CACE,MAAS,oBACT,IAAO,sDACP,KAAQ,MACV,EACA,CACE,MAAS,qBACT,IAAO,8CACP,KAAQ,QACV,EACD,CACD,KAAQ,qEACV,EACD,CACD,SAAY,CACV,MAAS,6BACT,MAAS,mGACT,YAAe,6DACjB,EACA,MAAS,CACP,KAAQ,cACR,YAAe,+DACf,KAAQ,UACV,CACF,EACA,CACE,GAAM,aACN,MAAS,iCACT,MAAS,eACT,kBAAqB,EACrB,QAAW,qFACX,QAAW,CACT,CACE,MAAS,iBACT,UAAa,kEACb,UAAa,CACX,CACE,MAAS,6BACT,IAAO,yEACP,KAAQ,MACV,EACA,CACE,MAAS,0BACT,IAAO,2DACP,KAAQ,MACV,EACA,CACE,MAAS,yBACT,IAAO,4CACP,KAAQ,QACV,EACD,CACD,KAAQ,6EACV,EACA,CACE,MAAS,0BACT,UAAa,kDACb,UAAa,CACX,CACE,MAAS,2BACT,IAAO,6DACP,KAAQ,MACV,EACA,CACE,MAAS,4BACT,IAAO,mCACP,KAAQ,SACV,EACA,CACE,MAAS,2BACT,IAAO,8EACP,KAAQ,QACV,EACD,CACD,KAAQ,sFACV,EACA,CACE,MAAS,sBACT,UAAa,iEACb,UAAa,CACX,CACE,MAAS,uBACT,IAAO,+BACP,KAAQ,MACV,EACA,CACE,MAAS,2BACT,IAAO,uCACP,KAAQ,MACV,EACA,CACE,MAAS,wBACT,IAAO,8CACP,KAAQ,QACV,EACD,CACD,KAAQ,oFACV,EACD,CACD,SAAY,CACV,MAAS,oBACT,MAAS,oGACT,YAAe,4DACjB,EACA,MAAS,CACP,KAAQ,qBACR,YAAe,qDACf,KAAQ,UACV,CACF,EACA,CACE,GAAM,YACN,MAAS,+BACT,MAAS,WACT,kBAAqB,EACrB,QAAW,qGACX,QAAW,CACT,CACE,MAAS,sBACT,UAAa,8DACb,UAAa,CACX,CACE,MAAS,gCACT,IAAO,yDACP,KAAQ,MACV,EACA,CACE,MAAS,6BACT,IAAO,wDACP,KAAQ,QACV,EACA,CACE,MAAS,qBACT,IAAO,gCACP,KAAQ,SACV,EACD,CACD,KAAQ,yFACV,EACA,CACE,MAAS,uBACT,UAAa,6DACb,UAAa,CACX,CACE,MAAS,oBACT,IAAO,2CACP,KAAQ,QACV,EACA,CACE,MAAS,6BACT,IAAO,sDACP,KAAQ,MACV,EACA,CACE,MAAS,0BACT,IAAO,uDACP,KAAQ,QACV,EACD,CACD,KAAQ,+EACV,EACA,CACE,MAAS,+BACT,UAAa,gEACb,UAAa,CACX,CACE,MAAS,2BACT,IAAO,uCACP,KAAQ,SACV,EACA,CACE,MAAS,qCACT,IAAO,oDACP,KAAQ,QACV,EACA,CACE,MAAS,yBACT,IAAO,2CACP,KAAQ,MACV,EACD,CACD,KAAQ,wFACV,EACD,CACD,SAAY,CACV,MAAS,8BACT,MAAS,qGACT,YAAe,2DACjB,EACA,MAAS,CACP,KAAQ,mBACR,YAAe,yEACf,KAAQ,OACV,CACF,EACA,CACE,GAAM,kBACN,MAAS,6BACT,MAAS,WACT,kBAAqB,EACrB,QAAW,kHACX,QAAW,CACT,CACE,MAAS,4BACT,UAAa,6DACb,UAAa,CACX,CACE,MAAS,yBACT,IAAO,yDACP,KAAQ,QACV,EACA,CACE,MAAS,yBACT,IAAO,0CACP,KAAQ,MACV,EACA,CACE,MAAS,+BACT,IAAO,mCACP,KAAQ,SACV,EACD,CACD,KAAQ,gEACV,EACA,CACE,MAAS,uBACT,UAAa,4DACb,UAAa,CACX,CACE,MAAS,kBACT,IAAO,iDACP,KAAQ,QACV,EACA,CACE,MAAS,uBACT,IAAO,uCACP,KAAQ,MACV,EACA,CACE,MAAS,uBACT,IAAO,iEACP,KAAQ,SACV,EACD,CACD,KAAQ,4EACV,EACA,CACE,MAAS,wBACT,UAAa,sDACb,UAAa,CACX,CACE,MAAS,kCACT,IAAO,4CACP,KAAQ,SACV,EACA,CACE,MAAS,iCACT,IAAO,wDACP,KAAQ,MACV,EACA,CACE,MAAS,wBACT,IAAO,sCACP,KAAQ,QACV,EACD,CACD,KAAQ,2EACV,EACD,CACD,SAAY,CACV,MAAS,wBACT,MAAS,uFACT,YAAe,0EACjB,EACA,MAAS,CACP,KAAQ,oBACR,YAAe,yDACf,KAAQ,SACV,CACF,EACD"}